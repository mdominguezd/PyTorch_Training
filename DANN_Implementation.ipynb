{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba30470-4b9f-4873-a1c4-93fe657548cf",
   "metadata": {},
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff18998-d388-4514-9b84-79a771ccc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b04138-eca8-4e5b-9ef7-305ed7133475",
   "metadata": {},
   "source": [
    "# mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee47c53-0a37-493d-bcb8-a259b4bc2823",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SubsetRandomSampler, DataLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import params\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.29730626, 0.29918741, 0.27534935),\n",
    "                                                     (0.32780124, 0.32292358, 0.32056796)),\n",
    "                                ])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=True, download=True,\n",
    "                                     transform=transform)\n",
    "mnist_valid_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=True, download=True,\n",
    "                                     transform=transforms)\n",
    "mnist_test_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=False, transform=transform)\n",
    "\n",
    "indices = list(range(len(mnist_train_dataset)))\n",
    "validation_size = 5000\n",
    "train_idx, valid_idx = indices[validation_size:], indices[:validation_size]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "mnist_train_loader = DataLoader(\n",
    "    mnist_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "mnist_valid_loader = DataLoader(\n",
    "    mnist_valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "mnist_test_loader = DataLoader(\n",
    "    mnist_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "\n",
    "# mnist_train_all = (mnist_train_dataset.train_data[5000:].reshape(55000, 28, 28, 1))\n",
    "# mnist_concat = torch.cat((mnist_train_all, mnist_train_all, mnist_train_all), 3)\n",
    "# print(mnist_test_dataset.test_labels.shape, mnist_test_dataset.test_labels)\n",
    "\n",
    "\n",
    "def one_hot_embedding(labels, num_classes=10):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "\n",
    "# print(one_hot_embedding(mnist_test_dataset.test_labels))\n",
    "\n",
    "# print(mnist_concat.shape)\n",
    "\n",
    "\n",
    "# def test():\n",
    "    # print(mnist_train_loader.shape)\n",
    "    # print(len(train_sampler), len(mnist_test_loader), len(valid_sampler))\n",
    "    # print(len(mnist_train_loader), len(mnist_valid_loader), len(mnist_test_loader))\n",
    "    # for i, train_data in enumerate(mnist_train_loader):\n",
    "    #     img, label = train_data\n",
    "    #     print(img.shape)\n",
    "    # for i in range(1):\n",
    "    #     # for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "    #     #     print(i, batch_idx, labels, len(labels))\n",
    "    # mnist_train_all = (mnist_train_dataset.train_data[5000:].reshape(55000, 28, 28, 1))\n",
    "    # mnist_concat = torch.cat((mnist_train_all, mnist_train_all, mnist_train_all), 3)\n",
    "    # print(mnist_concat.shape)\n",
    "    # print(list(mnist_train_dataset.train_data[5000:].size()))\n",
    "    # print(mnist_train_dataset.train_data.float().mean()/255)\n",
    "    # print(mnist_train_dataset.train_data.float().std()/255)\n",
    "    # for batch_idx, (train_data, test_data) in enumerate(zip(mnist_train_loader, mnist_valid_loader)):\n",
    "    #     train_image, train_label = train_data\n",
    "    #     test_image, test_label = test_data\n",
    "    #     print(train_image.shape)\n",
    "    #     # print(train_label, len(train_label))\n",
    "    #     # print(test_label, len(test_label))\n",
    "    #     # exit()\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bd09d-8ada-4aa6-9857-a4422dd98e07",
   "metadata": {},
   "source": [
    "# mnistm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33dbfe-2aaf-4fac-bb9e-89407fb7c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import os\n",
    "import errno\n",
    "from PIL import Image\n",
    "import params\n",
    "\n",
    "\n",
    "# MNIST-M\n",
    "class MNISTM(data.Dataset):\n",
    "    \"\"\"`MNIST-M Dataset.\"\"\"\n",
    "\n",
    "    url = \"https://github.com/VanushVaswani/keras_mnistm/releases/download/1.0/keras_mnistm.pkl.gz\"\n",
    "\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'mnist_m_train.pt'\n",
    "    test_file = 'mnist_m_test.pt'\n",
    "\n",
    "    def __init__(self,\n",
    "                 root, mnist_root=\"data\",\n",
    "                 train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=False):\n",
    "        \"\"\"Init MNIST-M dataset.\"\"\"\n",
    "        super(MNISTM, self).__init__()\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.mnist_root = os.path.expanduser(mnist_root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = \\\n",
    "                torch.load(os.path.join(self.root,\n",
    "                                        self.processed_folder,\n",
    "                                        self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = \\\n",
    "                torch.load(os.path.join(self.root,\n",
    "                                        self.processed_folder,\n",
    "                                        self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get images and target for data loader.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        # print(type(img))\n",
    "        img = Image.fromarray(img.squeeze().numpy(), mode='RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return size of dataset.\"\"\"\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root,\n",
    "                                           self.processed_folder,\n",
    "                                           self.training_file)) and \\\n",
    "               os.path.exists(os.path.join(self.root,\n",
    "                                           self.processed_folder,\n",
    "                                           self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"Download the MNIST data.\"\"\"\n",
    "        # import essential packages\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "        import pickle\n",
    "        from torchvision import datasets\n",
    "\n",
    "        # check if dataset already exists\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # make data dirs\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # download pkl files\n",
    "        print('Downloading ' + self.url)\n",
    "        filename = self.url.rpartition('/')[2]\n",
    "        file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "        if not os.path.exists(file_path.replace('.gz', '')):\n",
    "            data = urllib.request.urlopen(self.url)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        # load MNIST-M images from pkl file\n",
    "        with open(file_path.replace('.gz', ''), \"rb\") as f:\n",
    "            mnist_m_data = pickle.load(f, encoding='bytes')\n",
    "        mnist_m_train_data = torch.ByteTensor(mnist_m_data[b'train'])\n",
    "        mnist_m_test_data = torch.ByteTensor(mnist_m_data[b'test'])\n",
    "\n",
    "        # get MNIST labels\n",
    "        mnist_train_labels = datasets.MNIST(root=self.mnist_root,\n",
    "                                            train=True,\n",
    "                                            download=True).train_labels\n",
    "        mnist_test_labels = datasets.MNIST(root=self.mnist_root,\n",
    "                                           train=False,\n",
    "                                           download=True).test_labels\n",
    "\n",
    "        # save MNIST-M dataset\n",
    "        training_set = (mnist_m_train_data, mnist_train_labels)\n",
    "        test_set = (mnist_m_test_data, mnist_test_labels)\n",
    "        with open(os.path.join(self.root,\n",
    "                               self.processed_folder,\n",
    "                               self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root,\n",
    "                               self.processed_folder,\n",
    "                               self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('MNISTM Done!')\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.29730626, 0.29918741, 0.27534935),\n",
    "                                                     (0.32780124, 0.32292358, 0.32056796))\n",
    "                                ])\n",
    "\n",
    "mnistm_train_dataset = MNISTM(root='data/pytorch/MNIST-M', train=True, download=True,\n",
    "                              transform=transform)\n",
    "mnistm_valid_dataset = MNISTM(root='data/pytorch/MNIST-M', train=True, download=True,\n",
    "                              transform=transform)\n",
    "mnistm_test_dataset = MNISTM(root='data/pytorch/MNIST-M', train=False, transform=transform)\n",
    "\n",
    "indices = list(range(len(mnistm_train_dataset)))\n",
    "validation_size = 5000\n",
    "train_idx, valid_idx = indices[validation_size:], indices[:validation_size]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "mnistm_train_loader = DataLoader(\n",
    "    mnistm_train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "mnistm_valid_loader = DataLoader(\n",
    "    mnistm_valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "mnistm_test_loader = DataLoader(\n",
    "    mnistm_test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "# print(mnistm_train_dataset.train_data[5000:].shape)\n",
    "# mnistm_concat = (mnistm_train_dataset.train_data[5000:])\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     print(mnistm_train_dataset.train_data[5000:].shape)\n",
    "#     print((mnistm_train_dataset.train_data[5000:].size()))\n",
    "#\n",
    "#     print(len(train_sampler), len(mnistm_test_loader), len(valid_sampler))\n",
    "#     print(len(mnistm_train_loader), len(mnistm_valid_loader), len(mnistm_test_loader))\n",
    "#     for i in range(1):\n",
    "#         for batch_idx, (inputs, labels) in enumerate(mnistm_train_loader):\n",
    "#             print(i, batch_idx, labels, len(labels))\n",
    "#     for batch_idx, (train_data, test_data) in enumerate(zip(mnistm_train_loader, mnistm_valid_loader)):\n",
    "#         train_image, train_label = train_data\n",
    "#         test_image, test_label = test_data\n",
    "#         print(train_label, len(train_label))\n",
    "#         print(test_label, len(test_label))\n",
    "#         exit()\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc02f5-7800-4d8f-ba7e-a36e4ef824e8",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecc5f5-55e6-4eca-b11d-417d83b5d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Function\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "\n",
    "def optimizer_scheduler(optimizer, p):\n",
    "    \"\"\"\n",
    "    Adjust the learning rate of optimizer\n",
    "    :param optimizer: optimizer for updating parameters\n",
    "    :param p: a variable for adjusting learning rate\n",
    "    :return: optimizer\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def one_hot_embedding(labels, num_classes=10):\n",
    "    \"\"\"Embedding labels to one-hot form.\n",
    "\n",
    "    Args:\n",
    "      labels: (LongTensor) class labels, sized [N,].\n",
    "      num_classes: (int) number of classes.\n",
    "\n",
    "    Returns:\n",
    "      (tensor) encoded labels, sized [N, #classes].\n",
    "    \"\"\"\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "\n",
    "def save_model(encoder, classifier, discriminator, training_mode, save_name):\n",
    "    print('Save models ...')\n",
    "\n",
    "    save_folder = 'trained_models'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    torch.save(encoder.state_dict(), 'trained_models/encoder_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
    "    torch.save(classifier.state_dict(), 'trained_models/classifier_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
    "\n",
    "    if training_mode == 'dann':\n",
    "        torch.save(discriminator.state_dict(), 'trained_models/discriminator_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
    "\n",
    "    print('Model is saved !!!')\n",
    "\n",
    "\n",
    "def plot_embedding(X, y, d, training_mode, save_name):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    y = list(itertools.chain.from_iterable(y))\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(d)):  # X.shape[0] : 1024\n",
    "        # plot colored number\n",
    "        if d[i] == 0:\n",
    "            colors = (0.0, 0.0, 1.0, 1.0)\n",
    "        else:\n",
    "            colors = (1.0, 0.0, 0.0, 1.0)\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=colors,\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if save_name is not None:\n",
    "        plt.title(save_name)\n",
    "\n",
    "    save_folder = 'saved_plot'\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    fig_name = 'saved_plot/' + str(training_mode) + '_' + str(save_name) + '.png'\n",
    "    plt.savefig(fig_name)\n",
    "    print('{} is saved'.format(fig_name))\n",
    "\n",
    "\n",
    "def visualize(encoder, training_mode, save_name):\n",
    "    # Draw 512 samples in test_data\n",
    "    source_test_loader = mnist_test_loader\n",
    "    target_test_loader = mnistm_test_loader\n",
    "\n",
    "    # Get source_test samples\n",
    "    source_label_list = []\n",
    "    source_img_list = []\n",
    "    for i, test_data in enumerate(source_test_loader):\n",
    "        if i >= 16:  # to get only 512 samples\n",
    "            break\n",
    "        img, label = test_data\n",
    "        label = label.numpy()\n",
    "        img = img.cuda()\n",
    "        img = torch.cat((img, img, img), 1)  # MNIST channel 1 -> 3\n",
    "        source_label_list.append(label)\n",
    "        source_img_list.append(img)\n",
    "\n",
    "    source_img_list = torch.stack(source_img_list)\n",
    "    source_img_list = source_img_list.view(-1, 3, 28, 28)\n",
    "\n",
    "    # Get target_test samples\n",
    "    target_label_list = []\n",
    "    target_img_list = []\n",
    "    for i, test_data in enumerate(target_test_loader):\n",
    "        if i >= 16:\n",
    "            break\n",
    "        img, label = test_data\n",
    "        label = label.numpy()\n",
    "        img = img.cuda()\n",
    "        target_label_list.append(label)\n",
    "        target_img_list.append(img)\n",
    "\n",
    "    target_img_list = torch.stack(target_img_list)\n",
    "    target_img_list = target_img_list.view(-1, 3, 28, 28)\n",
    "\n",
    "    # Stack source_list + target_list\n",
    "    combined_label_list = source_label_list\n",
    "    combined_label_list.extend(target_label_list)\n",
    "    combined_img_list = torch.cat((source_img_list, target_img_list), 0)\n",
    "\n",
    "    source_domain_list = torch.zeros(512).type(torch.LongTensor)\n",
    "    target_domain_list = torch.ones(512).type(torch.LongTensor)\n",
    "    combined_domain_list = torch.cat((source_domain_list, target_domain_list), 0).cuda()\n",
    "\n",
    "    print(\"Extract features to draw T-SNE plot...\")\n",
    "    combined_feature = encoder(combined_img_list)  # combined_feature : 1024,2352\n",
    "\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
    "    dann_tsne = tsne.fit_transform(combined_feature.detach().cpu().numpy())\n",
    "\n",
    "    print('Draw plot ...')\n",
    "    save_name = save_name + '_' + str(training_mode)\n",
    "    plot_embedding(dann_tsne, combined_label_list, combined_domain_list, training_mode, save_name)\n",
    "\n",
    "\n",
    "def visualize_input():\n",
    "    source_test_loader = mnist_test_loader\n",
    "    target_test_loader = mnistm_test_loader\n",
    "\n",
    "    # Get source_test samples\n",
    "    source_label_list = []\n",
    "    source_img_list = []\n",
    "    for i, test_data in enumerate(source_test_loader):\n",
    "        if i >= 16:  # to get only 512 samples\n",
    "            break\n",
    "        img, label = test_data\n",
    "        label = label.numpy()\n",
    "        img = img.cuda()\n",
    "        img = torch.cat((img, img, img), 1)  # MNIST channel 1 -> 3\n",
    "        source_label_list.append(label)\n",
    "        source_img_list.append(img)\n",
    "\n",
    "    source_img_list = torch.stack(source_img_list)\n",
    "    source_img_list = source_img_list.view(-1, 3, 28, 28)\n",
    "\n",
    "    # Get target_test samples\n",
    "    target_label_list = []\n",
    "    target_img_list = []\n",
    "    for i, test_data in enumerate(target_test_loader):\n",
    "        if i >= 16:\n",
    "            break\n",
    "        img, label = test_data\n",
    "        label = label.numpy()\n",
    "        img = img.cuda()\n",
    "        target_label_list.append(label)\n",
    "        target_img_list.append(img)\n",
    "\n",
    "    target_img_list = torch.stack(target_img_list)\n",
    "    target_img_list = target_img_list.view(-1, 3, 28, 28)\n",
    "\n",
    "    # Stack source_list + target_list\n",
    "    combined_label_list = source_label_list\n",
    "    combined_label_list.extend(target_label_list)\n",
    "    combined_img_list = torch.cat((source_img_list, target_img_list), 0)\n",
    "\n",
    "    source_domain_list = torch.zeros(512).type(torch.LongTensor)\n",
    "    target_domain_list = torch.ones(512).type(torch.LongTensor)\n",
    "    combined_domain_list = torch.cat((source_domain_list, target_domain_list), 0).cuda()\n",
    "\n",
    "    print(\"Extract features to draw T-SNE plot...\")\n",
    "    combined_feature = combined_img_list  # combined_feature : 1024,3,28,28\n",
    "    combined_feature = combined_feature.view(1024, -1)  # flatten\n",
    "    # print(type(combined_feature), combined_feature.shape)\n",
    "\n",
    "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
    "    dann_tsne = tsne.fit_transform(combined_feature.detach().cpu().numpy())\n",
    "    print('Draw plot ...')\n",
    "    save_name = 'input_tsne_plot'\n",
    "    plot_embedding(dann_tsne, combined_label_list, combined_domain_list, 'input', 'mnist_n_mnistM')\n",
    "\n",
    "\n",
    "def get_free_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    # memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    return 0\n",
    "\n",
    "def set_model_mode(mode='train', models=None):\n",
    "    for model in models:\n",
    "        if mode == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307273e-5ea5-4592-8940-2a3612ffd22c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ad254-19d0-46fe-adc4-49c287d906f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Extractor, self).__init__()\n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = x.view(-1, 3 * 28 * 28)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=3 * 28 * 28, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return F.softmax(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(in_features=3 * 28 * 28, out_features=100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=100, out_features=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_feature, alpha):\n",
    "        reversed_input = ReverseLayerF.apply(input_feature, alpha)\n",
    "        x = self.discriminator(reversed_input)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6c2d5-7a9e-4484-8894-950b5d14e2c6",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b18ea-8719-465d-b346-435b798bc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from utils import set_model_mode\n",
    "\n",
    "def tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode):\n",
    "    print(\"Model test ...\")\n",
    "\n",
    "    encoder.cuda()\n",
    "    classifier.cuda()\n",
    "    set_model_mode('eval', [encoder, classifier])\n",
    "    \n",
    "    if training_mode == 'dann':\n",
    "        discriminator.cuda()\n",
    "        set_model_mode('eval', [discriminator])\n",
    "        domain_correct = 0\n",
    "\n",
    "    source_correct = 0\n",
    "    target_correct = 0\n",
    "\n",
    "    for batch_idx, (source_data, target_data) in enumerate(zip(source_test_loader, target_test_loader)):\n",
    "        p = float(batch_idx) / len(source_test_loader)\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # 1. Source input -> Source Classification\n",
    "        source_image, source_label = source_data\n",
    "        source_image, source_label = source_image.cuda(), source_label.cuda()\n",
    "        source_image = torch.cat((source_image, source_image, source_image), 1)  # MNIST convert to 3 channel\n",
    "        source_feature = encoder(source_image)\n",
    "        source_output = classifier(source_feature)\n",
    "        source_pred = source_output.data.max(1, keepdim=True)[1]\n",
    "        source_correct += source_pred.eq(source_label.data.view_as(source_pred)).cpu().sum()\n",
    "\n",
    "        # 2. Target input -> Target Classification\n",
    "        target_image, target_label = target_data\n",
    "        target_image, target_label = target_image.cuda(), target_label.cuda()\n",
    "        target_feature = encoder(target_image)\n",
    "        target_output = classifier(target_feature)\n",
    "        target_pred = target_output.data.max(1, keepdim=True)[1]\n",
    "        target_correct += target_pred.eq(target_label.data.view_as(target_pred)).cpu().sum()\n",
    "\n",
    "        if training_mode == 'dann':\n",
    "            # 3. Combined input -> Domain Classificaion\n",
    "            combined_image = torch.cat((source_image, target_image), 0)  # 64 = (S:32 + T:32)\n",
    "            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n",
    "            domain_feature = encoder(combined_image)\n",
    "            domain_output = discriminator(domain_feature, alpha)\n",
    "            domain_pred = domain_output.data.max(1, keepdim=True)[1]\n",
    "            domain_correct += domain_pred.eq(domain_combined_label.data.view_as(domain_pred)).cpu().sum()\n",
    "\n",
    "    if training_mode == 'dann':\n",
    "        print(\"Test Results on DANN :\")\n",
    "        print('\\nSource Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              'Target Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              'Domain Accuracy: {}/{} ({:.2f}%)\\n'.\n",
    "            format(\n",
    "            source_correct, len(source_test_loader.dataset), 100. * source_correct.item() / len(source_test_loader.dataset),\n",
    "            target_correct, len(target_test_loader.dataset), 100. * target_correct.item() / len(target_test_loader.dataset),\n",
    "            domain_correct, len(source_test_loader.dataset) + len(target_test_loader.dataset), 100. * domain_correct.item() / (len(source_test_loader.dataset) + len(target_test_loader.dataset))\n",
    "        ))\n",
    "    else:\n",
    "        print(\"Test results on source_only :\")\n",
    "        print('\\nSource Accuracy: {}/{} ({:.2f}%)\\n'\n",
    "              'Target Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            source_correct, len(source_test_loader.dataset), 100. * source_correct.item() / len(source_test_loader.dataset),\n",
    "            target_correct, len(target_test_loader.dataset), 100. * target_correct.item() / len(target_test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e27be3-1300-4053-88a9-7be48e3ce211",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9a26e-b178-4c25-830a-a097dac60477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import params\n",
    "\n",
    "# Source : 0, Target :1\n",
    "source_test_loader = mnist_test_loader\n",
    "target_test_loader = mnistm_test_loader\n",
    "\n",
    "\n",
    "def source_only(encoder, classifier, source_train_loader, target_train_loader, save_name):\n",
    "    print(\"Source-only training\")\n",
    "    classifier_criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = optim.SGD(\n",
    "        list(encoder.parameters()) +\n",
    "        list(classifier.parameters()),\n",
    "        lr=0.01, momentum=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch))\n",
    "        set_model_mode('train', [encoder, classifier])\n",
    "\n",
    "        start_steps = epoch * len(source_train_loader)\n",
    "        total_steps = epochs * len(target_train_loader)\n",
    "        \n",
    "        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "            source_image, source_label = source_data\n",
    "            p = float(batch_idx + start_steps) / total_steps\n",
    "\n",
    "            source_image = torch.cat((source_image, source_image, source_image), 1)  # MNIST convert to 3 channel\n",
    "            source_image, source_label = source_image.cuda(), source_label.cuda()  # 32\n",
    "\n",
    "            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            source_feature = encoder(source_image)\n",
    "\n",
    "            # Classification loss\n",
    "            class_pred = classifier(source_feature)\n",
    "            class_loss = classifier_criterion(class_pred, source_label)\n",
    "\n",
    "            class_loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print('[{}/{} ({:.0f}%)]\\tClass Loss: {:.6f}'.format(batch_idx * len(source_image), len(source_train_loader.dataset), 100. * batch_idx / len(source_train_loader), class_loss.item()))\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            tester(encoder, classifier, None, source_test_loader, target_test_loader, training_mode='source_only')\n",
    "    save_model(encoder, classifier, None, 'source', save_name)\n",
    "    visualize(encoder, 'source', save_name)\n",
    "\n",
    "\n",
    "def dann(encoder, classifier, discriminator, source_train_loader, target_train_loader, save_name):\n",
    "    print(\"DANN training\")\n",
    "    \n",
    "    classifier_criterion = nn.CrossEntropyLoss().cuda()\n",
    "    discriminator_criterion = nn.CrossEntropyLoss().cuda()\n",
    "    \n",
    "    optimizer = optim.SGD(\n",
    "    list(encoder.parameters()) +\n",
    "    list(classifier.parameters()) +\n",
    "    list(discriminator.parameters()),\n",
    "    lr=0.01,\n",
    "    momentum=0.9)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch : {}'.format(epoch))\n",
    "        set_model_mode('train', [encoder, classifier, discriminator])\n",
    "\n",
    "        start_steps = epoch * len(source_train_loader)\n",
    "        total_steps = epochs * len(target_train_loader)\n",
    "        \n",
    "        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n",
    "\n",
    "            source_image, source_label = source_data\n",
    "            target_image, target_label = target_data\n",
    "\n",
    "            p = float(batch_idx + start_steps) / total_steps\n",
    "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "            source_image = torch.cat((source_image, source_image, source_image), 1)\n",
    "\n",
    "            source_image, source_label = source_image.cuda(), source_label.cuda()\n",
    "            target_image, target_label = target_image.cuda(), target_label.cuda()\n",
    "            combined_image = torch.cat((source_image, target_image), 0)\n",
    "\n",
    "            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            combined_feature = encoder(combined_image)\n",
    "            source_feature = encoder(source_image)\n",
    "\n",
    "            # 1.Classification loss\n",
    "            class_pred = classifier(source_feature)\n",
    "            class_loss = classifier_criterion(class_pred, source_label)\n",
    "\n",
    "            # 2. Domain loss\n",
    "            domain_pred = discriminator(combined_feature, alpha)\n",
    "\n",
    "            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n",
    "            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n",
    "            domain_loss = discriminator_criterion(domain_pred, domain_combined_label)\n",
    "\n",
    "            total_loss = class_loss + domain_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tClass Loss: {:.6f}\\tDomain Loss: {:.6f}'.format(\n",
    "                    batch_idx * len(target_image), len(target_train_loader.dataset), 100. * batch_idx / len(target_train_loader), total_loss.item(), class_loss.item(), domain_loss.item()))\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode='dann')\n",
    "\n",
    "    save_model(encoder, classifier, discriminator, 'source', save_name)\n",
    "    visualize(encoder, 'source', save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e269390-5906-43b7-97dc-7e7296d3e3d7",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87d5c5-cfd8-4168-b170-a2c5293546be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import train\n",
    "from utils import get_free_gpu\n",
    "\n",
    "save_name = 'omg'\n",
    "\n",
    "def main():\n",
    "    source_train_loader = mnist_train_loader\n",
    "    target_train_loader = mnistm_train_loader\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        get_free_gpu()\n",
    "        print('Running GPU : {}'.format(torch.cuda.current_device()))\n",
    "        encoder = Extractor().cuda()\n",
    "        classifier = Classifier().cuda()\n",
    "        discriminator = Discriminator().cuda()\n",
    "\n",
    "        train.source_only(encoder, classifier, source_train_loader, target_train_loader, save_name)\n",
    "        train.dann(encoder, classifier, discriminator, source_train_loader, target_train_loader, save_name)\n",
    "\n",
    "    else:\n",
    "        print(\"There is no GPU -_-!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
