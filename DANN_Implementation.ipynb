{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6ba30470-4b9f-4873-a1c4-93fe657548cf",
      "metadata": {
        "id": "6ba30470-4b9f-4873-a1c4-93fe657548cf"
      },
      "source": [
        "# params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ff18998-d388-4514-9b84-79a771ccc62e",
      "metadata": {
        "id": "4ff18998-d388-4514-9b84-79a771ccc62e"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "num_workers = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b04138-eca8-4e5b-9ef7-305ed7133475",
      "metadata": {
        "id": "67b04138-eca8-4e5b-9ef7-305ed7133475"
      },
      "source": [
        "# mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aee47c53-0a37-493d-bcb8-a259b4bc2823",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "id": "aee47c53-0a37-493d-bcb8-a259b4bc2823",
        "outputId": "87110fbe-7954-4cf9-d869-7741c40a9d17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 113971318.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/pytorch/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 111337953.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/pytorch/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35632761.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/pytorch/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2283141.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/pytorch/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/pytorch/MNIST/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))\n",
        "                                ])\n",
        "\n",
        "mnist_train_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=True, download=True,\n",
        "                                     transform=transform)\n",
        "mnist_valid_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=True, download=True,\n",
        "                                     transform=transforms)\n",
        "mnist_test_dataset = datasets.MNIST(root='data/pytorch/MNIST', train=False, transform=transform)\n",
        "\n",
        "indices = list(range(len(mnist_train_dataset)))\n",
        "validation_size = 5000\n",
        "train_idx, valid_idx = indices[validation_size:], indices[:validation_size]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "mnist_train_loader = DataLoader(\n",
        "    mnist_train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "mnist_valid_loader = DataLoader(\n",
        "    mnist_valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "mnist_test_loader = DataLoader(\n",
        "    mnist_test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "\n",
        "# mnist_train_all = (mnist_train_dataset.train_data[5000:].reshape(55000, 28, 28, 1))\n",
        "# mnist_concat = torch.cat((mnist_train_all, mnist_train_all, mnist_train_all), 3)\n",
        "# print(mnist_test_dataset.test_labels.shape, mnist_test_dataset.test_labels)\n",
        "\n",
        "\n",
        "def one_hot_embedding(labels, num_classes=10):\n",
        "    \"\"\"Embedding labels to one-hot form.\n",
        "\n",
        "    Args:\n",
        "      labels: (LongTensor) class labels, sized [N,].\n",
        "      num_classes: (int) number of classes.\n",
        "\n",
        "    Returns:\n",
        "      (tensor) encoded labels, sized [N, #classes].\n",
        "    \"\"\"\n",
        "    y = torch.eye(num_classes)\n",
        "    return y[labels]\n",
        "\n",
        "\n",
        "# print(one_hot_embedding(mnist_test_dataset.test_labels))\n",
        "\n",
        "# print(mnist_concat.shape)\n",
        "\n",
        "\n",
        "# def test():\n",
        "    # print(mnist_train_loader.shape)\n",
        "    # print(len(train_sampler), len(mnist_test_loader), len(valid_sampler))\n",
        "    # print(len(mnist_train_loader), len(mnist_valid_loader), len(mnist_test_loader))\n",
        "    # for i, train_data in enumerate(mnist_train_loader):\n",
        "    #     img, label = train_data\n",
        "    #     print(img.shape)\n",
        "    # for i in range(1):\n",
        "    #     # for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "    #     #     print(i, batch_idx, labels, len(labels))\n",
        "    # mnist_train_all = (mnist_train_dataset.train_data[5000:].reshape(55000, 28, 28, 1))\n",
        "    # mnist_concat = torch.cat((mnist_train_all, mnist_train_all, mnist_train_all), 3)\n",
        "    # print(mnist_concat.shape)\n",
        "    # print(list(mnist_train_dataset.train_data[5000:].size()))\n",
        "    # print(mnist_train_dataset.train_data.float().mean()/255)\n",
        "    # print(mnist_train_dataset.train_data.float().std()/255)\n",
        "    # for batch_idx, (train_data, test_data) in enumerate(zip(mnist_train_loader, mnist_valid_loader)):\n",
        "    #     train_image, train_label = train_data\n",
        "    #     test_image, test_label = test_data\n",
        "    #     print(train_image.shape)\n",
        "    #     # print(train_label, len(train_label))\n",
        "    #     # print(test_label, len(test_label))\n",
        "    #     # exit()\n",
        "\n",
        "# test()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907bd09d-8ada-4aa6-9857-a4422dd98e07",
      "metadata": {
        "id": "907bd09d-8ada-4aa6-9857-a4422dd98e07"
      },
      "source": [
        "# mnistm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a33dbfe-2aaf-4fac-bb9e-89407fb7c167",
      "metadata": {
        "id": "3a33dbfe-2aaf-4fac-bb9e-89407fb7c167",
        "outputId": "80142432-97e6-46e8-aacc-363e998e1260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/VanushVaswani/keras_mnistm/releases/download/1.0/keras_mnistm.pkl.gz\n",
            "Processing...\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 99758403.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 56817867.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 29807692.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20011059.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNISTM Done!\n"
          ]
        }
      ],
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import os\n",
        "import errno\n",
        "from PIL import Image\n",
        "\n",
        "# MNIST-M\n",
        "class MNISTM(data.Dataset):\n",
        "    \"\"\"`MNIST-M Dataset.\"\"\"\n",
        "\n",
        "    url = \"https://github.com/VanushVaswani/keras_mnistm/releases/download/1.0/keras_mnistm.pkl.gz\"\n",
        "\n",
        "    raw_folder = 'raw'\n",
        "    processed_folder = 'processed'\n",
        "    training_file = 'mnist_m_train.pt'\n",
        "    test_file = 'mnist_m_test.pt'\n",
        "\n",
        "    def __init__(self,\n",
        "                 root, mnist_root=\"data\",\n",
        "                 train=True,\n",
        "                 transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        \"\"\"Init MNIST-M dataset.\"\"\"\n",
        "        super(MNISTM, self).__init__()\n",
        "        self.root = os.path.expanduser(root)\n",
        "        self.mnist_root = os.path.expanduser(mnist_root)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train = train  # training set or test set\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError('Dataset not found.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        if self.train:\n",
        "            self.train_data, self.train_labels = \\\n",
        "                torch.load(os.path.join(self.root,\n",
        "                                        self.processed_folder,\n",
        "                                        self.training_file))\n",
        "        else:\n",
        "            self.test_data, self.test_labels = \\\n",
        "                torch.load(os.path.join(self.root,\n",
        "                                        self.processed_folder,\n",
        "                                        self.test_file))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get images and target for data loader.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        if self.train:\n",
        "            img, target = self.train_data[index], self.train_labels[index]\n",
        "        else:\n",
        "            img, target = self.test_data[index], self.test_labels[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        # print(type(img))\n",
        "        img = Image.fromarray(img.squeeze().numpy(), mode='RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return size of dataset.\"\"\"\n",
        "        if self.train:\n",
        "            return len(self.train_data)\n",
        "        else:\n",
        "            return len(self.test_data)\n",
        "\n",
        "    def _check_exists(self):\n",
        "        return os.path.exists(os.path.join(self.root,\n",
        "                                           self.processed_folder,\n",
        "                                           self.training_file)) and \\\n",
        "               os.path.exists(os.path.join(self.root,\n",
        "                                           self.processed_folder,\n",
        "                                           self.test_file))\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the MNIST data.\"\"\"\n",
        "        # import essential packages\n",
        "        from six.moves import urllib\n",
        "        import gzip\n",
        "        import pickle\n",
        "        from torchvision import datasets\n",
        "\n",
        "        # check if dataset already exists\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        # make data dirs\n",
        "        try:\n",
        "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
        "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                pass\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "        # download pkl files\n",
        "        print('Downloading ' + self.url)\n",
        "        filename = self.url.rpartition('/')[2]\n",
        "        file_path = os.path.join(self.root, self.raw_folder, filename)\n",
        "        if not os.path.exists(file_path.replace('.gz', '')):\n",
        "            data = urllib.request.urlopen(self.url)\n",
        "            with open(file_path, 'wb') as f:\n",
        "                f.write(data.read())\n",
        "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
        "                    gzip.GzipFile(file_path) as zip_f:\n",
        "                out_f.write(zip_f.read())\n",
        "            os.unlink(file_path)\n",
        "\n",
        "        # process and save as torch files\n",
        "        print('Processing...')\n",
        "\n",
        "        # load MNIST-M images from pkl file\n",
        "        with open(file_path.replace('.gz', ''), \"rb\") as f:\n",
        "            mnist_m_data = pickle.load(f, encoding='bytes')\n",
        "        mnist_m_train_data = torch.ByteTensor(mnist_m_data[b'train'])\n",
        "        mnist_m_test_data = torch.ByteTensor(mnist_m_data[b'test'])\n",
        "\n",
        "        # get MNIST labels\n",
        "        mnist_train_labels = datasets.MNIST(root=self.mnist_root,\n",
        "                                            train=True,\n",
        "                                            download=True).train_labels\n",
        "        mnist_test_labels = datasets.MNIST(root=self.mnist_root,\n",
        "                                           train=False,\n",
        "                                           download=True).test_labels\n",
        "\n",
        "        # save MNIST-M dataset\n",
        "        training_set = (mnist_m_train_data, mnist_train_labels)\n",
        "        test_set = (mnist_m_test_data, mnist_test_labels)\n",
        "        with open(os.path.join(self.root,\n",
        "                               self.processed_folder,\n",
        "                               self.training_file), 'wb') as f:\n",
        "            torch.save(training_set, f)\n",
        "        with open(os.path.join(self.root,\n",
        "                               self.processed_folder,\n",
        "                               self.test_file), 'wb') as f:\n",
        "            torch.save(test_set, f)\n",
        "\n",
        "        print('MNISTM Done!')\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.29730626, 0.29918741, 0.27534935),\n",
        "                                                     (0.32780124, 0.32292358, 0.32056796))\n",
        "                                ])\n",
        "\n",
        "mnistm_train_dataset = MNISTM(root='data/pytorch/MNIST-M', train=True, download=True,\n",
        "                              transform=transform)\n",
        "mnistm_valid_dataset = MNISTM(root='data/pytorch/MNIST-M', train=True, download=True,\n",
        "                              transform=transform)\n",
        "mnistm_test_dataset = MNISTM(root='data/pytorch/MNIST-M', train=False, transform=transform)\n",
        "\n",
        "indices = list(range(len(mnistm_train_dataset)))\n",
        "validation_size = 5000\n",
        "train_idx, valid_idx = indices[validation_size:], indices[:validation_size]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "mnistm_train_loader = DataLoader(\n",
        "    mnistm_train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "mnistm_valid_loader = DataLoader(\n",
        "    mnistm_valid_dataset,\n",
        "    batch_size=batch_size,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "mnistm_test_loader = DataLoader(\n",
        "    mnistm_test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "# print(mnistm_train_dataset.train_data[5000:].shape)\n",
        "# mnistm_concat = (mnistm_train_dataset.train_data[5000:])\n",
        "\n",
        "\n",
        "# def test():\n",
        "#     print(mnistm_train_dataset.train_data[5000:].shape)\n",
        "#     print((mnistm_train_dataset.train_data[5000:].size()))\n",
        "#\n",
        "#     print(len(train_sampler), len(mnistm_test_loader), len(valid_sampler))\n",
        "#     print(len(mnistm_train_loader), len(mnistm_valid_loader), len(mnistm_test_loader))\n",
        "#     for i in range(1):\n",
        "#         for batch_idx, (inputs, labels) in enumerate(mnistm_train_loader):\n",
        "#             print(i, batch_idx, labels, len(labels))\n",
        "#     for batch_idx, (train_data, test_data) in enumerate(zip(mnistm_train_loader, mnistm_valid_loader)):\n",
        "#         train_image, train_label = train_data\n",
        "#         test_image, test_label = test_data\n",
        "#         print(train_label, len(train_label))\n",
        "#         print(test_label, len(test_label))\n",
        "#         exit()\n",
        "\n",
        "# test()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ecc02f5-7800-4d8f-ba7e-a36e4ef824e8",
      "metadata": {
        "id": "8ecc02f5-7800-4d8f-ba7e-a36e4ef824e8"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "25ecc5f5-55e6-4eca-b11d-417d83b5d138",
      "metadata": {
        "id": "25ecc5f5-55e6-4eca-b11d-417d83b5d138"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Function\n",
        "from sklearn.manifold import TSNE\n",
        "import torch\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "\n",
        "def optimizer_scheduler(optimizer, p):\n",
        "    \"\"\"\n",
        "    Adjust the learning rate of optimizer\n",
        "    :param optimizer: optimizer for updating parameters\n",
        "    :param p: a variable for adjusting learning rate\n",
        "    :return: optimizer\n",
        "    \"\"\"\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def one_hot_embedding(labels, num_classes=10):\n",
        "    \"\"\"Embedding labels to one-hot form.\n",
        "\n",
        "    Args:\n",
        "      labels: (LongTensor) class labels, sized [N,].\n",
        "      num_classes: (int) number of classes.\n",
        "\n",
        "    Returns:\n",
        "      (tensor) encoded labels, sized [N, #classes].\n",
        "    \"\"\"\n",
        "    y = torch.eye(num_classes)\n",
        "    return y[labels]\n",
        "\n",
        "\n",
        "def save_model(encoder, classifier, discriminator, training_mode, save_name):\n",
        "    print('Save models ...')\n",
        "\n",
        "    save_folder = 'trained_models'\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    torch.save(encoder.state_dict(), 'trained_models/encoder_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
        "    torch.save(classifier.state_dict(), 'trained_models/classifier_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
        "\n",
        "    if training_mode == 'dann':\n",
        "        torch.save(discriminator.state_dict(), 'trained_models/discriminator_' + str(training_mode) + '_' + str(save_name) + '.pt')\n",
        "\n",
        "    print('Model is saved !!!')\n",
        "\n",
        "\n",
        "def plot_embedding(X, y, d, training_mode, save_name):\n",
        "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "    X = (X - x_min) / (x_max - x_min)\n",
        "    y = list(itertools.chain.from_iterable(y))\n",
        "    y = np.asarray(y)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(len(d)):  # X.shape[0] : 1024\n",
        "        # plot colored number\n",
        "        if d[i] == 0:\n",
        "            colors = (0.0, 0.0, 1.0, 1.0)\n",
        "        else:\n",
        "            colors = (1.0, 0.0, 0.0, 1.0)\n",
        "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
        "                 color=colors,\n",
        "                 fontdict={'weight': 'bold', 'size': 9})\n",
        "\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    if save_name is not None:\n",
        "        plt.title(save_name)\n",
        "\n",
        "    save_folder = 'saved_plot'\n",
        "    if not os.path.exists(save_folder):\n",
        "        os.makedirs(save_folder)\n",
        "\n",
        "    fig_name = 'saved_plot/' + str(training_mode) + '_' + str(save_name) + '.png'\n",
        "    plt.savefig(fig_name)\n",
        "    print('{} is saved'.format(fig_name))\n",
        "\n",
        "\n",
        "def visualize(encoder, training_mode, save_name):\n",
        "    # Draw 512 samples in test_data\n",
        "    source_test_loader = mnist_test_loader\n",
        "    target_test_loader = mnistm_test_loader\n",
        "\n",
        "    # Get source_test samples\n",
        "    source_label_list = []\n",
        "    source_img_list = []\n",
        "    for i, test_data in enumerate(source_test_loader):\n",
        "        if i >= 16:  # to get only 512 samples\n",
        "            break\n",
        "        img, label = test_data\n",
        "        label = label.numpy()\n",
        "        img = img.cuda()\n",
        "        img = torch.cat((img, img, img), 1)  # MNIST channel 1 -> 3\n",
        "        source_label_list.append(label)\n",
        "        source_img_list.append(img)\n",
        "\n",
        "    source_img_list = torch.stack(source_img_list)\n",
        "    source_img_list = source_img_list.view(-1, 3, 28, 28)\n",
        "\n",
        "    # Get target_test samples\n",
        "    target_label_list = []\n",
        "    target_img_list = []\n",
        "    for i, test_data in enumerate(target_test_loader):\n",
        "        if i >= 16:\n",
        "            break\n",
        "        img, label = test_data\n",
        "        label = label.numpy()\n",
        "        img = img.cuda()\n",
        "        target_label_list.append(label)\n",
        "        target_img_list.append(img)\n",
        "\n",
        "    target_img_list = torch.stack(target_img_list)\n",
        "    target_img_list = target_img_list.view(-1, 3, 28, 28)\n",
        "\n",
        "    # Stack source_list + target_list\n",
        "    combined_label_list = source_label_list\n",
        "    combined_label_list.extend(target_label_list)\n",
        "    combined_img_list = torch.cat((source_img_list, target_img_list), 0)\n",
        "\n",
        "    source_domain_list = torch.zeros(512).type(torch.LongTensor)\n",
        "    target_domain_list = torch.ones(512).type(torch.LongTensor)\n",
        "    combined_domain_list = torch.cat((source_domain_list, target_domain_list), 0).cuda()\n",
        "\n",
        "    print(\"Extract features to draw T-SNE plot...\")\n",
        "    combined_feature = encoder(combined_img_list)  # combined_feature : 1024,2352\n",
        "\n",
        "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
        "    dann_tsne = tsne.fit_transform(combined_feature.detach().cpu().numpy())\n",
        "\n",
        "    print('Draw plot ...')\n",
        "    save_name = save_name + '_' + str(training_mode)\n",
        "    plot_embedding(dann_tsne, combined_label_list, combined_domain_list, training_mode, save_name)\n",
        "\n",
        "\n",
        "def visualize_input():\n",
        "    source_test_loader = mnist_test_loader\n",
        "    target_test_loader = mnistm_test_loader\n",
        "\n",
        "    # Get source_test samples\n",
        "    source_label_list = []\n",
        "    source_img_list = []\n",
        "    for i, test_data in enumerate(source_test_loader):\n",
        "        if i >= 16:  # to get only 512 samples\n",
        "            break\n",
        "        img, label = test_data\n",
        "        label = label.numpy()\n",
        "        img = img.cuda()\n",
        "        img = torch.cat((img, img, img), 1)  # MNIST channel 1 -> 3\n",
        "        source_label_list.append(label)\n",
        "        source_img_list.append(img)\n",
        "\n",
        "    source_img_list = torch.stack(source_img_list)\n",
        "    source_img_list = source_img_list.view(-1, 3, 28, 28)\n",
        "\n",
        "    # Get target_test samples\n",
        "    target_label_list = []\n",
        "    target_img_list = []\n",
        "    for i, test_data in enumerate(target_test_loader):\n",
        "        if i >= 16:\n",
        "            break\n",
        "        img, label = test_data\n",
        "        label = label.numpy()\n",
        "        img = img.cuda()\n",
        "        target_label_list.append(label)\n",
        "        target_img_list.append(img)\n",
        "\n",
        "    target_img_list = torch.stack(target_img_list)\n",
        "    target_img_list = target_img_list.view(-1, 3, 28, 28)\n",
        "\n",
        "    # Stack source_list + target_list\n",
        "    combined_label_list = source_label_list\n",
        "    combined_label_list.extend(target_label_list)\n",
        "    combined_img_list = torch.cat((source_img_list, target_img_list), 0)\n",
        "\n",
        "    source_domain_list = torch.zeros(512).type(torch.LongTensor)\n",
        "    target_domain_list = torch.ones(512).type(torch.LongTensor)\n",
        "    combined_domain_list = torch.cat((source_domain_list, target_domain_list), 0).cuda()\n",
        "\n",
        "    print(\"Extract features to draw T-SNE plot...\")\n",
        "    combined_feature = combined_img_list  # combined_feature : 1024,3,28,28\n",
        "    combined_feature = combined_feature.view(1024, -1)  # flatten\n",
        "    # print(type(combined_feature), combined_feature.shape)\n",
        "\n",
        "    tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
        "    dann_tsne = tsne.fit_transform(combined_feature.detach().cpu().numpy())\n",
        "    print('Draw plot ...')\n",
        "    save_name = 'input_tsne_plot'\n",
        "    plot_embedding(dann_tsne, combined_label_list, combined_domain_list, 'input', 'mnist_n_mnistM')\n",
        "\n",
        "\n",
        "def get_free_gpu():\n",
        "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
        "    # memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
        "    return 0\n",
        "\n",
        "def set_model_mode(mode='train', models=None):\n",
        "    for model in models:\n",
        "        if mode == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e307273e-5ea5-4592-8940-2a3612ffd22c",
      "metadata": {
        "id": "e307273e-5ea5-4592-8940-2a3612ffd22c"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a9ad254-19d0-46fe-adc4-49c287d906f5",
      "metadata": {
        "id": "3a9ad254-19d0-46fe-adc4-49c287d906f5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Extractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Extractor, self).__init__()\n",
        "        self.extractor = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.extractor(x)\n",
        "        x = x.view(-1, 3 * 28 * 28)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=3 * 28 * 28, out_features=100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=100, out_features=100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=100, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return F.softmax(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(in_features=3 * 28 * 28, out_features=100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=100, out_features=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_feature, alpha):\n",
        "        reversed_input = ReverseLayerF.apply(input_feature, alpha)\n",
        "        x = self.discriminator(reversed_input)\n",
        "        return F.softmax(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b6c2d5-7a9e-4484-8894-950b5d14e2c6",
      "metadata": {
        "id": "d7b6c2d5-7a9e-4484-8894-950b5d14e2c6"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af4b18ea-8719-465d-b346-435b798bc550",
      "metadata": {
        "id": "af4b18ea-8719-465d-b346-435b798bc550"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode):\n",
        "    print(\"Model test ...\")\n",
        "\n",
        "    encoder.cuda()\n",
        "    classifier.cuda()\n",
        "    set_model_mode('eval', [encoder, classifier])\n",
        "\n",
        "    if training_mode == 'dann':\n",
        "        discriminator.cuda()\n",
        "        set_model_mode('eval', [discriminator])\n",
        "        domain_correct = 0\n",
        "\n",
        "    source_correct = 0\n",
        "    target_correct = 0\n",
        "\n",
        "    for batch_idx, (source_data, target_data) in enumerate(zip(source_test_loader, target_test_loader)):\n",
        "        p = float(batch_idx) / len(source_test_loader)\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        # 1. Source input -> Source Classification\n",
        "        source_image, source_label = source_data\n",
        "        source_image, source_label = source_image.cuda(), source_label.cuda()\n",
        "        source_image = torch.cat((source_image, source_image, source_image), 1)  # MNIST convert to 3 channel\n",
        "        source_feature = encoder(source_image)\n",
        "        source_output = classifier(source_feature)\n",
        "        source_pred = source_output.data.max(1, keepdim=True)[1]\n",
        "        source_correct += source_pred.eq(source_label.data.view_as(source_pred)).cpu().sum()\n",
        "\n",
        "        # 2. Target input -> Target Classification\n",
        "        target_image, target_label = target_data\n",
        "        target_image, target_label = target_image.cuda(), target_label.cuda()\n",
        "        target_feature = encoder(target_image)\n",
        "        target_output = classifier(target_feature)\n",
        "        target_pred = target_output.data.max(1, keepdim=True)[1]\n",
        "        target_correct += target_pred.eq(target_label.data.view_as(target_pred)).cpu().sum()\n",
        "\n",
        "        if training_mode == 'dann':\n",
        "            # 3. Combined input -> Domain Classificaion\n",
        "            combined_image = torch.cat((source_image, target_image), 0)  # 64 = (S:32 + T:32)\n",
        "            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n",
        "            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n",
        "            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n",
        "            domain_feature = encoder(combined_image)\n",
        "            domain_output = discriminator(domain_feature, alpha)\n",
        "            domain_pred = domain_output.data.max(1, keepdim=True)[1]\n",
        "            domain_correct += domain_pred.eq(domain_combined_label.data.view_as(domain_pred)).cpu().sum()\n",
        "\n",
        "    if training_mode == 'dann':\n",
        "        print(\"Test Results on DANN :\")\n",
        "        print('\\nSource Accuracy: {}/{} ({:.2f}%)\\n'\n",
        "              'Target Accuracy: {}/{} ({:.2f}%)\\n'\n",
        "              'Domain Accuracy: {}/{} ({:.2f}%)\\n'.\n",
        "            format(\n",
        "            source_correct, len(source_test_loader.dataset), 100. * source_correct.item() / len(source_test_loader.dataset),\n",
        "            target_correct, len(target_test_loader.dataset), 100. * target_correct.item() / len(target_test_loader.dataset),\n",
        "            domain_correct, len(source_test_loader.dataset) + len(target_test_loader.dataset), 100. * domain_correct.item() / (len(source_test_loader.dataset) + len(target_test_loader.dataset))\n",
        "        ))\n",
        "    else:\n",
        "        print(\"Test results on source_only :\")\n",
        "        print('\\nSource Accuracy: {}/{} ({:.2f}%)\\n'\n",
        "              'Target Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "            source_correct, len(source_test_loader.dataset), 100. * source_correct.item() / len(source_test_loader.dataset),\n",
        "            target_correct, len(target_test_loader.dataset), 100. * target_correct.item() / len(target_test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e27be3-1300-4053-88a9-7be48e3ce211",
      "metadata": {
        "id": "f7e27be3-1300-4053-88a9-7be48e3ce211"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "add9a26e-b178-4c25-830a-a097dac60477",
      "metadata": {
        "id": "add9a26e-b178-4c25-830a-a097dac60477"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Source : 0, Target :1\n",
        "source_test_loader = mnist_test_loader\n",
        "target_test_loader = mnistm_test_loader\n",
        "\n",
        "\n",
        "def source_only(encoder, classifier, source_train_loader, target_train_loader, save_name):\n",
        "    print(\"Source-only training\")\n",
        "    classifier_criterion = nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = optim.SGD(\n",
        "        list(encoder.parameters()) +\n",
        "        list(classifier.parameters()),\n",
        "        lr=0.01, momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch : {}'.format(epoch))\n",
        "        set_model_mode('train', [encoder, classifier])\n",
        "\n",
        "        start_steps = epoch * len(source_train_loader)\n",
        "        total_steps = epochs * len(target_train_loader)\n",
        "\n",
        "        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n",
        "            source_image, source_label = source_data\n",
        "            p = float(batch_idx + start_steps) / total_steps\n",
        "\n",
        "            source_image = torch.cat((source_image, source_image, source_image), 1)  # MNIST convert to 3 channel\n",
        "            source_image, source_label = source_image.cuda(), source_label.cuda()  # 32\n",
        "\n",
        "            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            source_feature = encoder(source_image)\n",
        "\n",
        "            # Classification loss\n",
        "            class_pred = classifier(source_feature)\n",
        "            class_loss = classifier_criterion(class_pred, source_label)\n",
        "\n",
        "            class_loss.backward()\n",
        "            optimizer.step()\n",
        "            if (batch_idx + 1) % 50 == 0:\n",
        "                print('[{}/{} ({:.0f}%)]\\tClass Loss: {:.6f}'.format(batch_idx * len(source_image), len(source_train_loader.dataset), 100. * batch_idx / len(source_train_loader), class_loss.item()))\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            tester(encoder, classifier, None, source_test_loader, target_test_loader, training_mode='source_only')\n",
        "    save_model(encoder, classifier, None, 'source', save_name)\n",
        "    visualize(encoder, 'source', save_name)\n",
        "\n",
        "\n",
        "def dann(encoder, classifier, discriminator, source_train_loader, target_train_loader, save_name):\n",
        "    print(\"DANN training\")\n",
        "\n",
        "    classifier_criterion = nn.CrossEntropyLoss().cuda()\n",
        "    discriminator_criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "    list(encoder.parameters()) +\n",
        "    list(classifier.parameters()) +\n",
        "    list(discriminator.parameters()),\n",
        "    lr=0.01,\n",
        "    momentum=0.9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch : {}'.format(epoch))\n",
        "        set_model_mode('train', [encoder, classifier, discriminator])\n",
        "\n",
        "        start_steps = epoch * len(source_train_loader)\n",
        "        total_steps = epochs * len(target_train_loader)\n",
        "\n",
        "        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n",
        "\n",
        "            source_image, source_label = source_data\n",
        "            target_image, target_label = target_data\n",
        "\n",
        "            p = float(batch_idx + start_steps) / total_steps\n",
        "            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "            source_image = torch.cat((source_image, source_image, source_image), 1)\n",
        "\n",
        "            source_image, source_label = source_image.cuda(), source_label.cuda()\n",
        "            target_image, target_label = target_image.cuda(), target_label.cuda()\n",
        "            combined_image = torch.cat((source_image, target_image), 0)\n",
        "\n",
        "            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            combined_feature = encoder(combined_image)\n",
        "            source_feature = encoder(source_image)\n",
        "\n",
        "            # 1.Classification loss\n",
        "            class_pred = classifier(source_feature)\n",
        "            class_loss = classifier_criterion(class_pred, source_label)\n",
        "\n",
        "            # 2. Domain loss\n",
        "            domain_pred = discriminator(combined_feature, alpha)\n",
        "\n",
        "            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n",
        "            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n",
        "            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n",
        "            domain_loss = discriminator_criterion(domain_pred, domain_combined_label)\n",
        "\n",
        "            total_loss = class_loss + domain_loss\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (batch_idx + 1) % 50 == 0:\n",
        "                print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tClass Loss: {:.6f}\\tDomain Loss: {:.6f}'.format(\n",
        "                    batch_idx * len(target_image), len(target_train_loader.dataset), 100. * batch_idx / len(target_train_loader), total_loss.item(), class_loss.item(), domain_loss.item()))\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode='dann')\n",
        "\n",
        "    save_model(encoder, classifier, discriminator, 'source', save_name)\n",
        "    visualize(encoder, 'source', save_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e269390-5906-43b7-97dc-7e7296d3e3d7",
      "metadata": {
        "id": "6e269390-5906-43b7-97dc-7e7296d3e3d7"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8a87d5c5-cfd8-4168-b170-a2c5293546be",
      "metadata": {
        "id": "8a87d5c5-cfd8-4168-b170-a2c5293546be",
        "outputId": "d025b7dc-f08b-4a95-d17c-104c95502d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running GPU : 0\n",
            "Source-only training\n",
            "Epoch : 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-5-5ea6f2a6f2c3>:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1568/60000 (3%)]\tClass Loss: 2.302197\n",
            "[3168/60000 (6%)]\tClass Loss: 2.301353\n",
            "[4768/60000 (9%)]\tClass Loss: 2.301336\n",
            "[6368/60000 (12%)]\tClass Loss: 2.298558\n",
            "[7968/60000 (14%)]\tClass Loss: 2.296515\n",
            "[9568/60000 (17%)]\tClass Loss: 2.292007\n",
            "[11168/60000 (20%)]\tClass Loss: 2.151260\n",
            "[12768/60000 (23%)]\tClass Loss: 1.990917\n",
            "[14368/60000 (26%)]\tClass Loss: 1.824315\n",
            "[15968/60000 (29%)]\tClass Loss: 1.752697\n",
            "[17568/60000 (32%)]\tClass Loss: 1.693865\n",
            "[19168/60000 (35%)]\tClass Loss: 1.628873\n",
            "[20768/60000 (38%)]\tClass Loss: 1.689252\n",
            "[22368/60000 (41%)]\tClass Loss: 1.507220\n",
            "[23968/60000 (44%)]\tClass Loss: 1.661531\n",
            "[25568/60000 (46%)]\tClass Loss: 1.556071\n",
            "[27168/60000 (49%)]\tClass Loss: 1.568343\n",
            "[28768/60000 (52%)]\tClass Loss: 1.606478\n",
            "[30368/60000 (55%)]\tClass Loss: 1.597251\n",
            "[31968/60000 (58%)]\tClass Loss: 1.657605\n",
            "[33568/60000 (61%)]\tClass Loss: 1.730018\n",
            "[35168/60000 (64%)]\tClass Loss: 1.612704\n",
            "[36768/60000 (67%)]\tClass Loss: 1.619692\n",
            "[38368/60000 (70%)]\tClass Loss: 1.554677\n",
            "[39968/60000 (73%)]\tClass Loss: 1.628857\n",
            "[41568/60000 (76%)]\tClass Loss: 1.463209\n",
            "[43168/60000 (78%)]\tClass Loss: 1.617031\n",
            "[44768/60000 (81%)]\tClass Loss: 1.638763\n",
            "[46368/60000 (84%)]\tClass Loss: 1.659063\n",
            "[47968/60000 (87%)]\tClass Loss: 1.566191\n",
            "[49568/60000 (90%)]\tClass Loss: 1.563048\n",
            "[51168/60000 (93%)]\tClass Loss: 1.476546\n",
            "[52768/60000 (96%)]\tClass Loss: 1.701224\n",
            "[54368/60000 (99%)]\tClass Loss: 1.561455\n",
            "Epoch : 1\n",
            "[1568/60000 (3%)]\tClass Loss: 1.650743\n",
            "[3168/60000 (6%)]\tClass Loss: 1.587816\n",
            "[4768/60000 (9%)]\tClass Loss: 1.566518\n",
            "[6368/60000 (12%)]\tClass Loss: 1.598291\n",
            "[7968/60000 (14%)]\tClass Loss: 1.547591\n",
            "[9568/60000 (17%)]\tClass Loss: 1.572040\n",
            "[11168/60000 (20%)]\tClass Loss: 1.625529\n",
            "[12768/60000 (23%)]\tClass Loss: 1.726128\n",
            "[14368/60000 (26%)]\tClass Loss: 1.554351\n",
            "[15968/60000 (29%)]\tClass Loss: 1.522030\n",
            "[17568/60000 (32%)]\tClass Loss: 1.517819\n",
            "[19168/60000 (35%)]\tClass Loss: 1.478929\n",
            "[20768/60000 (38%)]\tClass Loss: 1.503457\n",
            "[22368/60000 (41%)]\tClass Loss: 1.506251\n",
            "[23968/60000 (44%)]\tClass Loss: 1.496828\n",
            "[25568/60000 (46%)]\tClass Loss: 1.500167\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492398\n",
            "[28768/60000 (52%)]\tClass Loss: 1.464929\n",
            "[30368/60000 (55%)]\tClass Loss: 1.518582\n",
            "[31968/60000 (58%)]\tClass Loss: 1.498633\n",
            "[33568/60000 (61%)]\tClass Loss: 1.495716\n",
            "[35168/60000 (64%)]\tClass Loss: 1.489914\n",
            "[36768/60000 (67%)]\tClass Loss: 1.490232\n",
            "[38368/60000 (70%)]\tClass Loss: 1.482514\n",
            "[39968/60000 (73%)]\tClass Loss: 1.484144\n",
            "[41568/60000 (76%)]\tClass Loss: 1.494698\n",
            "[43168/60000 (78%)]\tClass Loss: 1.464869\n",
            "[44768/60000 (81%)]\tClass Loss: 1.483177\n",
            "[46368/60000 (84%)]\tClass Loss: 1.491216\n",
            "[47968/60000 (87%)]\tClass Loss: 1.468324\n",
            "[49568/60000 (90%)]\tClass Loss: 1.472670\n",
            "[51168/60000 (93%)]\tClass Loss: 1.466666\n",
            "[52768/60000 (96%)]\tClass Loss: 1.511268\n",
            "[54368/60000 (99%)]\tClass Loss: 1.492434\n",
            "Epoch : 2\n",
            "[1568/60000 (3%)]\tClass Loss: 1.468480\n",
            "[3168/60000 (6%)]\tClass Loss: 1.466482\n",
            "[4768/60000 (9%)]\tClass Loss: 1.464859\n",
            "[6368/60000 (12%)]\tClass Loss: 1.477207\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492138\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461226\n",
            "[11168/60000 (20%)]\tClass Loss: 1.469544\n",
            "[12768/60000 (23%)]\tClass Loss: 1.494607\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461621\n",
            "[15968/60000 (29%)]\tClass Loss: 1.486921\n",
            "[17568/60000 (32%)]\tClass Loss: 1.483055\n",
            "[19168/60000 (35%)]\tClass Loss: 1.502198\n",
            "[20768/60000 (38%)]\tClass Loss: 1.473181\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461156\n",
            "[23968/60000 (44%)]\tClass Loss: 1.493065\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461617\n",
            "[27168/60000 (49%)]\tClass Loss: 1.503420\n",
            "[28768/60000 (52%)]\tClass Loss: 1.462523\n",
            "[30368/60000 (55%)]\tClass Loss: 1.464209\n",
            "[31968/60000 (58%)]\tClass Loss: 1.491940\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461180\n",
            "[35168/60000 (64%)]\tClass Loss: 1.462583\n",
            "[36768/60000 (67%)]\tClass Loss: 1.496835\n",
            "[38368/60000 (70%)]\tClass Loss: 1.493940\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461209\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461171\n",
            "[43168/60000 (78%)]\tClass Loss: 1.462215\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461157\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492475\n",
            "[47968/60000 (87%)]\tClass Loss: 1.462871\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461217\n",
            "[51168/60000 (93%)]\tClass Loss: 1.464114\n",
            "[52768/60000 (96%)]\tClass Loss: 1.487741\n",
            "[54368/60000 (99%)]\tClass Loss: 1.532560\n",
            "Epoch : 3\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461153\n",
            "[3168/60000 (6%)]\tClass Loss: 1.462469\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461296\n",
            "[6368/60000 (12%)]\tClass Loss: 1.520159\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492402\n",
            "[9568/60000 (17%)]\tClass Loss: 1.471057\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461906\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492213\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461977\n",
            "[15968/60000 (29%)]\tClass Loss: 1.488580\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461250\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461484\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461318\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461776\n",
            "[23968/60000 (44%)]\tClass Loss: 1.469941\n",
            "[25568/60000 (46%)]\tClass Loss: 1.464120\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461235\n",
            "[28768/60000 (52%)]\tClass Loss: 1.492402\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461250\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492438\n",
            "[33568/60000 (61%)]\tClass Loss: 1.508453\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461188\n",
            "[36768/60000 (67%)]\tClass Loss: 1.518962\n",
            "[38368/60000 (70%)]\tClass Loss: 1.480711\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461336\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461181\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461154\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461957\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461412\n",
            "[47968/60000 (87%)]\tClass Loss: 1.499748\n",
            "[49568/60000 (90%)]\tClass Loss: 1.465356\n",
            "[51168/60000 (93%)]\tClass Loss: 1.465904\n",
            "[52768/60000 (96%)]\tClass Loss: 1.462292\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461745\n",
            "Epoch : 4\n",
            "[1568/60000 (3%)]\tClass Loss: 1.491038\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461175\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461157\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461222\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461194\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461163\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492352\n",
            "[12768/60000 (23%)]\tClass Loss: 1.494635\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461195\n",
            "[15968/60000 (29%)]\tClass Loss: 1.519565\n",
            "[17568/60000 (32%)]\tClass Loss: 1.467100\n",
            "[19168/60000 (35%)]\tClass Loss: 1.472864\n",
            "[20768/60000 (38%)]\tClass Loss: 1.481174\n",
            "[22368/60000 (41%)]\tClass Loss: 1.491553\n",
            "[23968/60000 (44%)]\tClass Loss: 1.469921\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461197\n",
            "[27168/60000 (49%)]\tClass Loss: 1.480799\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461262\n",
            "[30368/60000 (55%)]\tClass Loss: 1.462917\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461228\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461172\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461287\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492413\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492187\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461339\n",
            "[41568/60000 (76%)]\tClass Loss: 1.494655\n",
            "[43168/60000 (78%)]\tClass Loss: 1.490842\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461347\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461183\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461166\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461172\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492470\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461156\n",
            "Epoch : 5\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.491782\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461163\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461299\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461279\n",
            "[11168/60000 (20%)]\tClass Loss: 1.481102\n",
            "[12768/60000 (23%)]\tClass Loss: 1.490156\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461198\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461155\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461156\n",
            "[19168/60000 (35%)]\tClass Loss: 1.463915\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461817\n",
            "[22368/60000 (41%)]\tClass Loss: 1.510311\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461348\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.470017\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461153\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461464\n",
            "[31968/60000 (58%)]\tClass Loss: 1.486503\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461197\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461314\n",
            "[36768/60000 (67%)]\tClass Loss: 1.490412\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461425\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461306\n",
            "[43168/60000 (78%)]\tClass Loss: 1.469331\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461156\n",
            "[46368/60000 (84%)]\tClass Loss: 1.508491\n",
            "[47968/60000 (87%)]\tClass Loss: 1.478328\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461255\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461269\n",
            "[52768/60000 (96%)]\tClass Loss: 1.462557\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461153\n",
            "Epoch : 6\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461155\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.488319\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461171\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461156\n",
            "[9568/60000 (17%)]\tClass Loss: 1.465292\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492408\n",
            "[12768/60000 (23%)]\tClass Loss: 1.527852\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492928\n",
            "[15968/60000 (29%)]\tClass Loss: 1.477470\n",
            "[17568/60000 (32%)]\tClass Loss: 1.462851\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461353\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461308\n",
            "[22368/60000 (41%)]\tClass Loss: 1.462740\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461191\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461220\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461206\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461160\n",
            "[31968/60000 (58%)]\tClass Loss: 1.576671\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461225\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.489985\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461877\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461228\n",
            "[41568/60000 (76%)]\tClass Loss: 1.468940\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461276\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461158\n",
            "[46368/60000 (84%)]\tClass Loss: 1.466310\n",
            "[47968/60000 (87%)]\tClass Loss: 1.462356\n",
            "[49568/60000 (90%)]\tClass Loss: 1.489091\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461634\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461205\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461156\n",
            "Epoch : 7\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461296\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461167\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461155\n",
            "[7968/60000 (14%)]\tClass Loss: 1.472861\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461724\n",
            "[11168/60000 (20%)]\tClass Loss: 1.491867\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461162\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461159\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461185\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461748\n",
            "[19168/60000 (35%)]\tClass Loss: 1.521457\n",
            "[20768/60000 (38%)]\tClass Loss: 1.493222\n",
            "[22368/60000 (41%)]\tClass Loss: 1.462584\n",
            "[23968/60000 (44%)]\tClass Loss: 1.486923\n",
            "[25568/60000 (46%)]\tClass Loss: 1.462895\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.523633\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461178\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.462881\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492099\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492305\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461766\n",
            "[44768/60000 (81%)]\tClass Loss: 1.479083\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461764\n",
            "[47968/60000 (87%)]\tClass Loss: 1.466824\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492416\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461227\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492399\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461155\n",
            "Epoch : 8\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461172\n",
            "[3168/60000 (6%)]\tClass Loss: 1.491600\n",
            "[4768/60000 (9%)]\tClass Loss: 1.492479\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461153\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461193\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461160\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461156\n",
            "[12768/60000 (23%)]\tClass Loss: 1.488439\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461176\n",
            "[15968/60000 (29%)]\tClass Loss: 1.472097\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461154\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461155\n",
            "[20768/60000 (38%)]\tClass Loss: 1.462299\n",
            "[22368/60000 (41%)]\tClass Loss: 1.497137\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.493001\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492330\n",
            "[28768/60000 (52%)]\tClass Loss: 1.491829\n",
            "[30368/60000 (55%)]\tClass Loss: 1.480786\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461373\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461323\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.483861\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461159\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461153\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461350\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461165\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492370\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461155\n",
            "[51168/60000 (93%)]\tClass Loss: 1.474270\n",
            "[52768/60000 (96%)]\tClass Loss: 1.462747\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461164\n",
            "Epoch : 9\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461172\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492368\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461160\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492319\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461901\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492227\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461648\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461229\n",
            "[14368/60000 (26%)]\tClass Loss: 1.463399\n",
            "[15968/60000 (29%)]\tClass Loss: 1.499902\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461244\n",
            "[19168/60000 (35%)]\tClass Loss: 1.462637\n",
            "[20768/60000 (38%)]\tClass Loss: 1.467463\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461156\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461163\n",
            "[27168/60000 (49%)]\tClass Loss: 1.473274\n",
            "[28768/60000 (52%)]\tClass Loss: 1.496853\n",
            "[30368/60000 (55%)]\tClass Loss: 1.463094\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492395\n",
            "[33568/60000 (61%)]\tClass Loss: 1.509778\n",
            "[35168/60000 (64%)]\tClass Loss: 1.472075\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461350\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461156\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461154\n",
            "[41568/60000 (76%)]\tClass Loss: 1.463672\n",
            "[43168/60000 (78%)]\tClass Loss: 1.474499\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461157\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492383\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461245\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461444\n",
            "[52768/60000 (96%)]\tClass Loss: 1.491876\n",
            "[54368/60000 (99%)]\tClass Loss: 1.524055\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9905/10000 (99.05%)\n",
            "Target Accuracy: 6174/10000 (61.74%)\n",
            "\n",
            "Epoch : 10\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461525\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461857\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461207\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461153\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.462669\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461292\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.491776\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461162\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461172\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.477046\n",
            "[31968/60000 (58%)]\tClass Loss: 1.462013\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461153\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492502\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461841\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461177\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461327\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461169\n",
            "[46368/60000 (84%)]\tClass Loss: 1.468942\n",
            "[47968/60000 (87%)]\tClass Loss: 1.462769\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461216\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461223\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461430\n",
            "[54368/60000 (99%)]\tClass Loss: 1.466627\n",
            "Epoch : 11\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492401\n",
            "[4768/60000 (9%)]\tClass Loss: 1.468468\n",
            "[6368/60000 (12%)]\tClass Loss: 1.471496\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461155\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492415\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492385\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461178\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461157\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461156\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461186\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461218\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461161\n",
            "[25568/60000 (46%)]\tClass Loss: 1.462018\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461211\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461207\n",
            "[30368/60000 (55%)]\tClass Loss: 1.463251\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461157\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461331\n",
            "[35168/60000 (64%)]\tClass Loss: 1.484548\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461157\n",
            "[38368/60000 (70%)]\tClass Loss: 1.488569\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461233\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492398\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461522\n",
            "[44768/60000 (81%)]\tClass Loss: 1.471076\n",
            "[46368/60000 (84%)]\tClass Loss: 1.491906\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461225\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461155\n",
            "[51168/60000 (93%)]\tClass Loss: 1.492327\n",
            "[52768/60000 (96%)]\tClass Loss: 1.479480\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 12\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461185\n",
            "[3168/60000 (6%)]\tClass Loss: 1.463018\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461179\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461271\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.463307\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492442\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461156\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461328\n",
            "[15968/60000 (29%)]\tClass Loss: 1.462708\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461187\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461598\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461191\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461176\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.490434\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.498301\n",
            "[31968/60000 (58%)]\tClass Loss: 1.462760\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492399\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461313\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492077\n",
            "[38368/60000 (70%)]\tClass Loss: 1.491310\n",
            "[39968/60000 (73%)]\tClass Loss: 1.480493\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461157\n",
            "[43168/60000 (78%)]\tClass Loss: 1.462104\n",
            "[44768/60000 (81%)]\tClass Loss: 1.491697\n",
            "[46368/60000 (84%)]\tClass Loss: 1.462760\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461158\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.486996\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461256\n",
            "[54368/60000 (99%)]\tClass Loss: 1.465211\n",
            "Epoch : 13\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461156\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461232\n",
            "[4768/60000 (9%)]\tClass Loss: 1.462515\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461428\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461171\n",
            "[12768/60000 (23%)]\tClass Loss: 1.462716\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.469290\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492402\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461153\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461225\n",
            "[25568/60000 (46%)]\tClass Loss: 1.466122\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461237\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461276\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461197\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461152\n",
            "[36768/60000 (67%)]\tClass Loss: 1.491988\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461212\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461586\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461160\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461196\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461154\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461259\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461176\n",
            "Epoch : 14\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461195\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461195\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461156\n",
            "[7968/60000 (14%)]\tClass Loss: 1.462174\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461155\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461688\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461201\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461201\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492366\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461156\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461220\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.465945\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461155\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461153\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461156\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461308\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461203\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461169\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461173\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461274\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461305\n",
            "[47968/60000 (87%)]\tClass Loss: 1.493348\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461172\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.491622\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461375\n",
            "Epoch : 15\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461166\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461935\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461152\n",
            "[6368/60000 (12%)]\tClass Loss: 1.465626\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461456\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461163\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.462744\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461366\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461205\n",
            "[17568/60000 (32%)]\tClass Loss: 1.462523\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461158\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461178\n",
            "[22368/60000 (41%)]\tClass Loss: 1.465505\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461160\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461154\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492293\n",
            "[28768/60000 (52%)]\tClass Loss: 1.463572\n",
            "[30368/60000 (55%)]\tClass Loss: 1.489213\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.464566\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461158\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492338\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461168\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461165\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461180\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461182\n",
            "[49568/60000 (90%)]\tClass Loss: 1.491310\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461155\n",
            "Epoch : 16\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461166\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492380\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492544\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461154\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461179\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461366\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461283\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461154\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461185\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461982\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461281\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461454\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.492387\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461744\n",
            "[31968/60000 (58%)]\tClass Loss: 1.470253\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461157\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492399\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492581\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461416\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492401\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461153\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461167\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461209\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461277\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.463390\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492414\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461153\n",
            "Epoch : 17\n",
            "[1568/60000 (3%)]\tClass Loss: 1.472850\n",
            "[3168/60000 (6%)]\tClass Loss: 1.463516\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461166\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492692\n",
            "[9568/60000 (17%)]\tClass Loss: 1.462217\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461152\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492486\n",
            "[15968/60000 (29%)]\tClass Loss: 1.463813\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492640\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461181\n",
            "[20768/60000 (38%)]\tClass Loss: 1.522969\n",
            "[22368/60000 (41%)]\tClass Loss: 1.491696\n",
            "[23968/60000 (44%)]\tClass Loss: 1.493071\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461158\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461155\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461481\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461203\n",
            "[31968/60000 (58%)]\tClass Loss: 1.462049\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461523\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461159\n",
            "[36768/60000 (67%)]\tClass Loss: 1.465669\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461161\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461284\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461172\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461170\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461373\n",
            "[49568/60000 (90%)]\tClass Loss: 1.473411\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461709\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 18\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461174\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461161\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461153\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461316\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461547\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492573\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461244\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461154\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461192\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461185\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461495\n",
            "[28768/60000 (52%)]\tClass Loss: 1.492061\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461208\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.462386\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461162\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461797\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461156\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492350\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461185\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492424\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461209\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492402\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461155\n",
            "Epoch : 19\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.462482\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461486\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461166\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461408\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461300\n",
            "[14368/60000 (26%)]\tClass Loss: 1.463931\n",
            "[15968/60000 (29%)]\tClass Loss: 1.489949\n",
            "[17568/60000 (32%)]\tClass Loss: 1.498096\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461219\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461289\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461153\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461153\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461170\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461404\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461155\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461160\n",
            "[44768/60000 (81%)]\tClass Loss: 1.462692\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461184\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461156\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461156\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461260\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461526\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9913/10000 (99.13%)\n",
            "Target Accuracy: 6190/10000 (61.90%)\n",
            "\n",
            "Epoch : 20\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461407\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461161\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461154\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492498\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461331\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461264\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461157\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492381\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.462241\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461198\n",
            "[22368/60000 (41%)]\tClass Loss: 1.463632\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461158\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461172\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461167\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461152\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461154\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461159\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461209\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461323\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461154\n",
            "Epoch : 21\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461222\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492187\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461172\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461947\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461260\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461455\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461335\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461155\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461261\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461367\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461160\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.465546\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461154\n",
            "[36768/60000 (67%)]\tClass Loss: 1.478584\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461200\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461409\n",
            "[41568/60000 (76%)]\tClass Loss: 1.462480\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461210\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461244\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461164\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461153\n",
            "Epoch : 22\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461155\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461152\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492393\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492401\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492780\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461157\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492404\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461195\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.476776\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461251\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461154\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461153\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461264\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461165\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461153\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461160\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461195\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461180\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461189\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461156\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.465039\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461266\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461476\n",
            "[52768/60000 (96%)]\tClass Loss: 1.462057\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461168\n",
            "Epoch : 23\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461164\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461154\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461284\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461154\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461186\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461163\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.464810\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461156\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461355\n",
            "[30368/60000 (55%)]\tClass Loss: 1.463310\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461156\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461187\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461191\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461158\n",
            "[49568/60000 (90%)]\tClass Loss: 1.462298\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461210\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 24\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461160\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461244\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461219\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461208\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461164\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461154\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461258\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461169\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461255\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461322\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461340\n",
            "[28768/60000 (52%)]\tClass Loss: 1.463678\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461740\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461157\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461153\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461157\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461153\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461165\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461161\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 25\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461185\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461162\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461153\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461316\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461659\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461156\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461467\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492472\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461196\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461157\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461176\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461168\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461215\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461159\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461811\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461162\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461158\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492399\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461154\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 26\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461283\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461159\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461156\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461316\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461158\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461175\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461787\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461311\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461158\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461177\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461153\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461153\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461167\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461152\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461238\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461157\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461162\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461171\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461170\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492417\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461155\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461316\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 27\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461154\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461432\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461612\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461306\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461171\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461154\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461160\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461161\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461174\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461221\n",
            "[27168/60000 (49%)]\tClass Loss: 1.491572\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461393\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461159\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461153\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461155\n",
            "[43168/60000 (78%)]\tClass Loss: 1.492405\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461169\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492401\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461401\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461153\n",
            "Epoch : 28\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461164\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461197\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.491388\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461213\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461275\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461160\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461173\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461169\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461230\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461168\n",
            "[27168/60000 (49%)]\tClass Loss: 1.462033\n",
            "[28768/60000 (52%)]\tClass Loss: 1.522609\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461250\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461153\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461212\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461318\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461154\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461153\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461165\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461174\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461168\n",
            "Epoch : 29\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461240\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461255\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461164\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461435\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461174\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461202\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461261\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461155\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461184\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461159\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461158\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461159\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492390\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461157\n",
            "[30368/60000 (55%)]\tClass Loss: 1.491849\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461162\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461354\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461258\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461155\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461172\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461154\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461229\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461164\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461203\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461313\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9911/10000 (99.11%)\n",
            "Target Accuracy: 6247/10000 (62.47%)\n",
            "\n",
            "Epoch : 30\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461184\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461155\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461159\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461166\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461154\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461169\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461175\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492672\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461160\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461153\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461161\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461183\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461160\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461219\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461153\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492401\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461276\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461159\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461565\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461258\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492398\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461183\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461299\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492382\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 31\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461181\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492401\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.491227\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461175\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461165\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461296\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461222\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461164\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461173\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461163\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461169\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461155\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461182\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461375\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461249\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461193\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461155\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461156\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461229\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.491279\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461242\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461159\n",
            "[54368/60000 (99%)]\tClass Loss: 1.491799\n",
            "Epoch : 32\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461174\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492418\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461262\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461153\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492401\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461160\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461240\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461153\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461167\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461218\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461198\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461160\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461233\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461165\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461178\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461184\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461379\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492401\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461169\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461192\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461177\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 33\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461200\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.491492\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461173\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461156\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461166\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461440\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461154\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461186\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461174\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461153\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461152\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461162\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461154\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461163\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461154\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461164\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461175\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461419\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461165\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461653\n",
            "Epoch : 34\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461166\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461965\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461182\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492574\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461153\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461162\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461157\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461154\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461178\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461174\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461178\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461162\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461153\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461154\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461152\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461154\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.492472\n",
            "Epoch : 35\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461408\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461297\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461527\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492402\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461155\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492402\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461226\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492401\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461165\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461167\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461175\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461190\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461173\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461656\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461160\n",
            "[43168/60000 (78%)]\tClass Loss: 1.489999\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461161\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461157\n",
            "[47968/60000 (87%)]\tClass Loss: 1.462659\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492401\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461249\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 36\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461204\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461153\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461155\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461166\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461162\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461161\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461175\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461152\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461454\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461157\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461491\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461169\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461165\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461199\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461205\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461161\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461179\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461153\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461212\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461201\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461167\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 37\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461158\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.492400\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461159\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461193\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461152\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461161\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461160\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461156\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.462310\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461181\n",
            "[28768/60000 (52%)]\tClass Loss: 1.491814\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461165\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461243\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461154\n",
            "[36768/60000 (67%)]\tClass Loss: 1.522380\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461287\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461170\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461158\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461235\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461212\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461298\n",
            "Epoch : 38\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461159\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461160\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461185\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461174\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.492593\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461155\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461234\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461155\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461153\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461376\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492421\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461252\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.523651\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461212\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492495\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461156\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461169\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461234\n",
            "[54368/60000 (99%)]\tClass Loss: 1.492401\n",
            "Epoch : 39\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461160\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461155\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461191\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461155\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461153\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492430\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461156\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492369\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492401\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461155\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461164\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461296\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461190\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461191\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461159\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461173\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461154\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461177\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9915/10000 (99.15%)\n",
            "Target Accuracy: 6259/10000 (62.59%)\n",
            "\n",
            "Epoch : 40\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461267\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461163\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461327\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492406\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461195\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461195\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461152\n",
            "[28768/60000 (52%)]\tClass Loss: 1.492355\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461156\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461154\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461208\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461152\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461162\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461160\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461175\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461162\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461225\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.491358\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461210\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 41\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461162\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461155\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461154\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461180\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461153\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461154\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461155\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461204\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461158\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492380\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461155\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461156\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461260\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461183\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461160\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461168\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461320\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461395\n",
            "Epoch : 42\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461485\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492555\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461509\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461153\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461410\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461160\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461199\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492400\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461153\n",
            "[31968/60000 (58%)]\tClass Loss: 1.491436\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492401\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461161\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492432\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461157\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461239\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461249\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461175\n",
            "Epoch : 43\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461211\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461153\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461185\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461284\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461159\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461231\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461154\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461207\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461161\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461154\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461153\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461161\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461183\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461241\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492401\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461159\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461154\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461168\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492401\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461157\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461163\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 44\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461164\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461177\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461165\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461555\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461167\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461156\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461155\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461204\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492401\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461219\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461157\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461174\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461220\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461161\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461255\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461198\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461401\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461193\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461153\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461183\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461157\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 45\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461192\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461164\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461153\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461233\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461165\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461175\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461155\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461179\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461313\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461271\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461256\n",
            "[23968/60000 (44%)]\tClass Loss: 1.491250\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461154\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461174\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.522485\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492401\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461155\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461156\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461173\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461152\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461167\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461205\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461327\n",
            "Epoch : 46\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461155\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.491222\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461170\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461276\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461153\n",
            "[25568/60000 (46%)]\tClass Loss: 1.492435\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461155\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461200\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461172\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461241\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461174\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492401\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461160\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461155\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492468\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461163\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461156\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 47\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461178\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461153\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461161\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492400\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461296\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461182\n",
            "[15968/60000 (29%)]\tClass Loss: 1.462036\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461160\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461232\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461159\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.492356\n",
            "[25568/60000 (46%)]\tClass Loss: 1.492400\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461172\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461164\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461164\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461164\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461215\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461298\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461153\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461203\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461320\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461242\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461253\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 48\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492402\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461158\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461206\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461176\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461337\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461154\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461160\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461159\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461161\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461154\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461155\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461188\n",
            "[39968/60000 (73%)]\tClass Loss: 1.492426\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492402\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461158\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461154\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461154\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461155\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461165\n",
            "Epoch : 49\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461154\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461216\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461190\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461153\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461152\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461152\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461154\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461153\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461182\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492402\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461160\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461158\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461401\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461155\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461172\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461257\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461186\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461154\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461156\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461195\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461218\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9916/10000 (99.16%)\n",
            "Target Accuracy: 6249/10000 (62.49%)\n",
            "\n",
            "Epoch : 50\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461292\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492468\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.490772\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461187\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461152\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461164\n",
            "[25568/60000 (46%)]\tClass Loss: 1.492393\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461190\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461156\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461155\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461235\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461153\n",
            "Epoch : 51\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461154\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461158\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461201\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461153\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461153\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461237\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461220\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492406\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461189\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461179\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492113\n",
            "[28768/60000 (52%)]\tClass Loss: 1.492402\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461162\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461162\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461166\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492419\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461158\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461156\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492401\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461155\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461177\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461155\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 52\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461174\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461155\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461217\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461161\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461156\n",
            "[17568/60000 (32%)]\tClass Loss: 1.491267\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461157\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461164\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461202\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461152\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461178\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461155\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461171\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461156\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461240\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461165\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461188\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461203\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461178\n",
            "Epoch : 53\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461163\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461177\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461167\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461179\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461171\n",
            "[27168/60000 (49%)]\tClass Loss: 1.491379\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461160\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461160\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461152\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461159\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461162\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.491949\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461168\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461157\n",
            "Epoch : 54\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461165\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461177\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461154\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492495\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461171\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461160\n",
            "[19168/60000 (35%)]\tClass Loss: 1.492409\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461157\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461154\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461245\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461220\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461158\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461153\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461197\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461493\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 55\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461182\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461160\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492386\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461243\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461286\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461244\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461193\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461249\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461230\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492349\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461188\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.489851\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461501\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461297\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461156\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461153\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 56\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461157\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461190\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461193\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461223\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461152\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461152\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461154\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461201\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461163\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461179\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461203\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461218\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461172\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461241\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 57\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492401\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461176\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461159\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461163\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461453\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461176\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461156\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461229\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461238\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461157\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461153\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461157\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461168\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 58\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492401\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461161\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461159\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461168\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461184\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461152\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461168\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461168\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461156\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461174\n",
            "[27168/60000 (49%)]\tClass Loss: 1.491757\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461202\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461157\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492402\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461166\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461153\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461215\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461161\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461153\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492401\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461457\n",
            "[51168/60000 (93%)]\tClass Loss: 1.492401\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461160\n",
            "Epoch : 59\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461164\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461157\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461156\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492404\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461673\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461295\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461301\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461155\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461153\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461174\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461172\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.492401\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461312\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461299\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461171\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461162\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461161\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461166\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9917/10000 (99.17%)\n",
            "Target Accuracy: 6229/10000 (62.29%)\n",
            "\n",
            "Epoch : 60\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461166\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492403\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461159\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461158\n",
            "[22368/60000 (41%)]\tClass Loss: 1.492402\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461170\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461153\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461232\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461159\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461220\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461209\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461164\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461253\n",
            "[43168/60000 (78%)]\tClass Loss: 1.492413\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461153\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461159\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461168\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461152\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 61\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461193\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461154\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461154\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461250\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492353\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461154\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461161\n",
            "[25568/60000 (46%)]\tClass Loss: 1.492398\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461206\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461204\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461173\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461162\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461182\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461163\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492405\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492441\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461160\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461157\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461248\n",
            "Epoch : 62\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461256\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492401\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461156\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461217\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461173\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492401\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461160\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461160\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461157\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461152\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461240\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461154\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492401\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461191\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461157\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461169\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461183\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461153\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461154\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461166\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461190\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 63\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461152\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461156\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461164\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.491540\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461359\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.492379\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461156\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461153\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461275\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492612\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461159\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461161\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 64\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492403\n",
            "[3168/60000 (6%)]\tClass Loss: 1.492401\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461154\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461184\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492444\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461173\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461256\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461156\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461152\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461209\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461337\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461606\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461153\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461171\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461154\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461228\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461156\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461282\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.492349\n",
            "[52768/60000 (96%)]\tClass Loss: 1.491286\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 65\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461154\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461153\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461160\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461226\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461160\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461507\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492404\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461164\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461158\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461158\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461163\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461176\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461191\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461249\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461194\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461227\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461173\n",
            "Epoch : 66\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461155\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461177\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461170\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461167\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492419\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461192\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461220\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461163\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461156\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461258\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461152\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492407\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492390\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461157\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461158\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461256\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461170\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461164\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 67\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461254\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461179\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461195\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461200\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461163\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461152\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461153\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461160\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461158\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461157\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461159\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461157\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461167\n",
            "Epoch : 68\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461157\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461207\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.492403\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461228\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461368\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461212\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461155\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461157\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461176\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461243\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461156\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461202\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461258\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461233\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461159\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461187\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461156\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 69\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461159\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461186\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461164\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461155\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461158\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461152\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461245\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461157\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461177\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461241\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461366\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461154\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461154\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461185\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461154\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461181\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461170\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461153\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9916/10000 (99.16%)\n",
            "Target Accuracy: 6170/10000 (61.70%)\n",
            "\n",
            "Epoch : 70\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461158\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461155\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461161\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461156\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461178\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461156\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461158\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461161\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461195\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461156\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461168\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461155\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461220\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461161\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461154\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461321\n",
            "Epoch : 71\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492460\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461380\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461319\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461164\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461152\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461173\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.491190\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461188\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461187\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461203\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492401\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461179\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461184\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.491268\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461159\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461234\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461160\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461162\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 72\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461198\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461166\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461168\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461188\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461269\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461158\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461154\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461155\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492401\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461163\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461192\n",
            "[38368/60000 (70%)]\tClass Loss: 1.491266\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461261\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492402\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461159\n",
            "[51168/60000 (93%)]\tClass Loss: 1.492402\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461304\n",
            "Epoch : 73\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492424\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461182\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461171\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461153\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461197\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461153\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461185\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461185\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461258\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461168\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492417\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461208\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461186\n",
            "Epoch : 74\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461166\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461152\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461152\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461160\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461198\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461276\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461160\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461153\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461174\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461160\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461177\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461153\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461156\n",
            "[39968/60000 (73%)]\tClass Loss: 1.492401\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461160\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461355\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461156\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461169\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 75\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461209\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461169\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461161\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492402\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492399\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461162\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461736\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461156\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461237\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461182\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461154\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461172\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461160\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461154\n",
            "[38368/60000 (70%)]\tClass Loss: 1.492401\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461153\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461177\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492401\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 76\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461153\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461153\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461153\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461176\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461155\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461207\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461166\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461153\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461251\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461252\n",
            "[30368/60000 (55%)]\tClass Loss: 1.492371\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461299\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461164\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461192\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461204\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461155\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461168\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461170\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461190\n",
            "Epoch : 77\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461184\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461224\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461171\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461177\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461213\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461153\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461168\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461177\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461164\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461160\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461158\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461238\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461154\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461157\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461201\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461177\n",
            "Epoch : 78\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461153\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461154\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461158\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461180\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.492400\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461180\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461167\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461154\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461152\n",
            "[31968/60000 (58%)]\tClass Loss: 1.491278\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461154\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492404\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461237\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461161\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461208\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461223\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461166\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 79\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461169\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461158\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461152\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461155\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461170\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461160\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461156\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461259\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461199\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461178\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461178\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461167\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461154\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9913/10000 (99.13%)\n",
            "Target Accuracy: 6217/10000 (62.17%)\n",
            "\n",
            "Epoch : 80\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461177\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461195\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461175\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492401\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461155\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461155\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.492439\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461162\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461160\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461209\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461164\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461289\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461238\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461172\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461222\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461173\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461152\n",
            "[51168/60000 (93%)]\tClass Loss: 1.491276\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 81\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461242\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461171\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461181\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461162\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492363\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461176\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461155\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461161\n",
            "[23968/60000 (44%)]\tClass Loss: 1.492401\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461187\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492484\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461206\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461153\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492401\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461160\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461152\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461154\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461190\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492401\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461159\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 82\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492401\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461155\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492400\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461156\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461155\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461182\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461153\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461153\n",
            "[23968/60000 (44%)]\tClass Loss: 1.492401\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461158\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461153\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.491258\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461381\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461202\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461152\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461168\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461155\n",
            "[49568/60000 (90%)]\tClass Loss: 1.492406\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461153\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461157\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 83\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492401\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461152\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461153\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.491253\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461179\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461182\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461153\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461163\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461152\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461155\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461242\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461155\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461154\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461195\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461153\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461152\n",
            "[54368/60000 (99%)]\tClass Loss: 1.492401\n",
            "Epoch : 84\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461154\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461155\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461209\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461156\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492401\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461159\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461164\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461166\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461156\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461154\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461157\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461275\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461198\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.492401\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461310\n",
            "[39968/60000 (73%)]\tClass Loss: 1.492377\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492402\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461154\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.492401\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 85\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461185\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461175\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461171\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461163\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461170\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461168\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461154\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461153\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461155\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492438\n",
            "[47968/60000 (87%)]\tClass Loss: 1.492400\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461154\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461162\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 86\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461174\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461152\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461164\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461211\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.492401\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461154\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461158\n",
            "[22368/60000 (41%)]\tClass Loss: 1.492401\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461169\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461174\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461179\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461237\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461159\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461172\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461248\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461157\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461172\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 87\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461230\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461154\n",
            "[4768/60000 (9%)]\tClass Loss: 1.492401\n",
            "[6368/60000 (12%)]\tClass Loss: 1.492393\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461187\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461152\n",
            "[11168/60000 (20%)]\tClass Loss: 1.492401\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461225\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461152\n",
            "[27168/60000 (49%)]\tClass Loss: 1.492433\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461202\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461237\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461155\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461153\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461443\n",
            "[44768/60000 (81%)]\tClass Loss: 1.491260\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461247\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461153\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461160\n",
            "Epoch : 88\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461209\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461155\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461170\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461155\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461221\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.492401\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.523650\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461220\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461183\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461182\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461161\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461176\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461165\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461217\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461170\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461170\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461158\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461154\n",
            "Epoch : 89\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461164\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461154\n",
            "[9568/60000 (17%)]\tClass Loss: 1.492424\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461156\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461180\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461180\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.492403\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461201\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461453\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461153\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461154\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461192\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461157\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461202\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461154\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9916/10000 (99.16%)\n",
            "Target Accuracy: 6211/10000 (62.11%)\n",
            "\n",
            "Epoch : 90\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461169\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461181\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461154\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461176\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461154\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461184\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461152\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461152\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461177\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461154\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461154\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461171\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461219\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461160\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461153\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461182\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461177\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461275\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461178\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 91\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492403\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461152\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.523654\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461153\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.492401\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461152\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461153\n",
            "[23968/60000 (44%)]\tClass Loss: 1.492404\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461197\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.492393\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461156\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461160\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461153\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461163\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 92\n",
            "[1568/60000 (3%)]\tClass Loss: 1.492475\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461163\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461155\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461172\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461250\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461184\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461154\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461157\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.492406\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461158\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461168\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461155\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461155\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461152\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461204\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.491258\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461204\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461208\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461153\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 93\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461162\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461186\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461157\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461152\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461155\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.491287\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461199\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461212\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461159\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461159\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461172\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492401\n",
            "[46368/60000 (84%)]\tClass Loss: 1.492404\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461152\n",
            "[52768/60000 (96%)]\tClass Loss: 1.491269\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 94\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461151\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461167\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461172\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461297\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461151\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461152\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461156\n",
            "[15968/60000 (29%)]\tClass Loss: 1.491261\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461162\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461176\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461224\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461160\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461193\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461214\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461469\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461160\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461245\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461235\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461151\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 95\n",
            "[1568/60000 (3%)]\tClass Loss: 1.490936\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461226\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461152\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461200\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461155\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461175\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461159\n",
            "[12768/60000 (23%)]\tClass Loss: 1.492420\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461155\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461179\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461259\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492401\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461155\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461152\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461151\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461197\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461161\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461239\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461152\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461199\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461205\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492401\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 96\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461165\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461152\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.490922\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461157\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461156\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461184\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461220\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461157\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461175\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461152\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461231\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461152\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461180\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461157\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461196\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461152\n",
            "[43168/60000 (78%)]\tClass Loss: 1.491261\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461152\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461153\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461162\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461152\n",
            "Epoch : 97\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461152\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461152\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461151\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.462100\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461152\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461208\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461153\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461153\n",
            "[20768/60000 (38%)]\tClass Loss: 1.492398\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461151\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461151\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461151\n",
            "[33568/60000 (61%)]\tClass Loss: 1.462221\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461152\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461275\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461151\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461154\n",
            "[52768/60000 (96%)]\tClass Loss: 1.492400\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461154\n",
            "Epoch : 98\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461188\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461185\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461151\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461155\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461151\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461158\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461184\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461152\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461165\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461154\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461152\n",
            "[22368/60000 (41%)]\tClass Loss: 1.490867\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461151\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461156\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461151\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461282\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461157\n",
            "[33568/60000 (61%)]\tClass Loss: 1.461175\n",
            "[35168/60000 (64%)]\tClass Loss: 1.492401\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461168\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461151\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461151\n",
            "[44768/60000 (81%)]\tClass Loss: 1.461151\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461241\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461162\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461159\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461289\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Epoch : 99\n",
            "[1568/60000 (3%)]\tClass Loss: 1.461234\n",
            "[3168/60000 (6%)]\tClass Loss: 1.461151\n",
            "[4768/60000 (9%)]\tClass Loss: 1.461202\n",
            "[6368/60000 (12%)]\tClass Loss: 1.461163\n",
            "[7968/60000 (14%)]\tClass Loss: 1.461151\n",
            "[9568/60000 (17%)]\tClass Loss: 1.461210\n",
            "[11168/60000 (20%)]\tClass Loss: 1.461153\n",
            "[12768/60000 (23%)]\tClass Loss: 1.461151\n",
            "[14368/60000 (26%)]\tClass Loss: 1.461151\n",
            "[15968/60000 (29%)]\tClass Loss: 1.461151\n",
            "[17568/60000 (32%)]\tClass Loss: 1.461151\n",
            "[19168/60000 (35%)]\tClass Loss: 1.461151\n",
            "[20768/60000 (38%)]\tClass Loss: 1.461151\n",
            "[22368/60000 (41%)]\tClass Loss: 1.461152\n",
            "[23968/60000 (44%)]\tClass Loss: 1.461151\n",
            "[25568/60000 (46%)]\tClass Loss: 1.461153\n",
            "[27168/60000 (49%)]\tClass Loss: 1.461246\n",
            "[28768/60000 (52%)]\tClass Loss: 1.461190\n",
            "[30368/60000 (55%)]\tClass Loss: 1.461151\n",
            "[31968/60000 (58%)]\tClass Loss: 1.461156\n",
            "[33568/60000 (61%)]\tClass Loss: 1.492401\n",
            "[35168/60000 (64%)]\tClass Loss: 1.461151\n",
            "[36768/60000 (67%)]\tClass Loss: 1.461151\n",
            "[38368/60000 (70%)]\tClass Loss: 1.461151\n",
            "[39968/60000 (73%)]\tClass Loss: 1.461152\n",
            "[41568/60000 (76%)]\tClass Loss: 1.461151\n",
            "[43168/60000 (78%)]\tClass Loss: 1.461169\n",
            "[44768/60000 (81%)]\tClass Loss: 1.492407\n",
            "[46368/60000 (84%)]\tClass Loss: 1.461151\n",
            "[47968/60000 (87%)]\tClass Loss: 1.461151\n",
            "[49568/60000 (90%)]\tClass Loss: 1.461153\n",
            "[51168/60000 (93%)]\tClass Loss: 1.461151\n",
            "[52768/60000 (96%)]\tClass Loss: 1.461154\n",
            "[54368/60000 (99%)]\tClass Loss: 1.461151\n",
            "Model test ...\n",
            "Test results on source_only :\n",
            "\n",
            "Source Accuracy: 9915/10000 (99.15%)\n",
            "Target Accuracy: 6219/10000 (62.19%)\n",
            "\n",
            "Save models ...\n",
            "Model is saved !!!\n",
            "Extract features to draw T-SNE plot...\n",
            "Draw plot ...\n",
            "saved_plot/source_omg_source.png is saved\n",
            "DANN training\n",
            "Epoch : 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-5-5ea6f2a6f2c3>:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n",
            "<ipython-input-5-5ea6f2a6f2c3>:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1568/60000 (3%)]\tLoss: 2.624572\tClass Loss: 2.301872\tDomain Loss: 0.322700\n",
            "[3168/60000 (6%)]\tLoss: 2.616039\tClass Loss: 2.300068\tDomain Loss: 0.315971\n",
            "[4768/60000 (9%)]\tLoss: 2.623739\tClass Loss: 2.301893\tDomain Loss: 0.321846\n",
            "[6368/60000 (12%)]\tLoss: 2.611885\tClass Loss: 2.296568\tDomain Loss: 0.315316\n",
            "[7968/60000 (14%)]\tLoss: 2.611290\tClass Loss: 2.289105\tDomain Loss: 0.322184\n",
            "[9568/60000 (17%)]\tLoss: 2.593588\tClass Loss: 2.280043\tDomain Loss: 0.313545\n",
            "[11168/60000 (20%)]\tLoss: 2.446436\tClass Loss: 2.131442\tDomain Loss: 0.314994\n",
            "[12768/60000 (23%)]\tLoss: 2.036807\tClass Loss: 1.717966\tDomain Loss: 0.318841\n",
            "[14368/60000 (26%)]\tLoss: 2.051293\tClass Loss: 1.738030\tDomain Loss: 0.313263\n",
            "[15968/60000 (29%)]\tLoss: 1.963020\tClass Loss: 1.649750\tDomain Loss: 0.313270\n",
            "[17568/60000 (32%)]\tLoss: 1.940748\tClass Loss: 1.608689\tDomain Loss: 0.332059\n",
            "[19168/60000 (35%)]\tLoss: 1.912796\tClass Loss: 1.599281\tDomain Loss: 0.313516\n",
            "[20768/60000 (38%)]\tLoss: 1.995528\tClass Loss: 1.681925\tDomain Loss: 0.313603\n",
            "[22368/60000 (41%)]\tLoss: 1.941795\tClass Loss: 1.605306\tDomain Loss: 0.336489\n",
            "[23968/60000 (44%)]\tLoss: 1.852081\tClass Loss: 1.538818\tDomain Loss: 0.313262\n",
            "[25568/60000 (46%)]\tLoss: 1.878813\tClass Loss: 1.565551\tDomain Loss: 0.313262\n",
            "[27168/60000 (49%)]\tLoss: 2.003658\tClass Loss: 1.687429\tDomain Loss: 0.316229\n",
            "[28768/60000 (52%)]\tLoss: 1.868570\tClass Loss: 1.555301\tDomain Loss: 0.313268\n",
            "[30368/60000 (55%)]\tLoss: 1.823029\tClass Loss: 1.509763\tDomain Loss: 0.313266\n",
            "[31968/60000 (58%)]\tLoss: 1.831360\tClass Loss: 1.518097\tDomain Loss: 0.313263\n",
            "[33568/60000 (61%)]\tLoss: 1.846925\tClass Loss: 1.533662\tDomain Loss: 0.313263\n",
            "[35168/60000 (64%)]\tLoss: 1.813701\tClass Loss: 1.500433\tDomain Loss: 0.313268\n",
            "[36768/60000 (67%)]\tLoss: 1.775272\tClass Loss: 1.461998\tDomain Loss: 0.313274\n",
            "[38368/60000 (70%)]\tLoss: 1.875988\tClass Loss: 1.562689\tDomain Loss: 0.313299\n",
            "[39968/60000 (73%)]\tLoss: 1.810785\tClass Loss: 1.497516\tDomain Loss: 0.313269\n",
            "[41568/60000 (76%)]\tLoss: 1.804512\tClass Loss: 1.491245\tDomain Loss: 0.313267\n",
            "[43168/60000 (78%)]\tLoss: 1.795938\tClass Loss: 1.482650\tDomain Loss: 0.313287\n",
            "[44768/60000 (81%)]\tLoss: 1.839076\tClass Loss: 1.525807\tDomain Loss: 0.313269\n",
            "[46368/60000 (84%)]\tLoss: 1.816000\tClass Loss: 1.502737\tDomain Loss: 0.313264\n",
            "[47968/60000 (87%)]\tLoss: 1.844495\tClass Loss: 1.525190\tDomain Loss: 0.319304\n",
            "[49568/60000 (90%)]\tLoss: 1.819941\tClass Loss: 1.506679\tDomain Loss: 0.313262\n",
            "[51168/60000 (93%)]\tLoss: 1.805334\tClass Loss: 1.492072\tDomain Loss: 0.313263\n",
            "[52768/60000 (96%)]\tLoss: 1.813303\tClass Loss: 1.500025\tDomain Loss: 0.313278\n",
            "[54368/60000 (99%)]\tLoss: 1.778913\tClass Loss: 1.465647\tDomain Loss: 0.313265\n",
            "Epoch : 1\n",
            "[1568/60000 (3%)]\tLoss: 1.794902\tClass Loss: 1.481638\tDomain Loss: 0.313264\n",
            "[3168/60000 (6%)]\tLoss: 1.860690\tClass Loss: 1.547408\tDomain Loss: 0.313282\n",
            "[4768/60000 (9%)]\tLoss: 1.803781\tClass Loss: 1.490471\tDomain Loss: 0.313310\n",
            "[6368/60000 (12%)]\tLoss: 1.801868\tClass Loss: 1.488485\tDomain Loss: 0.313383\n",
            "[7968/60000 (14%)]\tLoss: 1.775028\tClass Loss: 1.461737\tDomain Loss: 0.313291\n",
            "[9568/60000 (17%)]\tLoss: 1.792382\tClass Loss: 1.479118\tDomain Loss: 0.313264\n",
            "[11168/60000 (20%)]\tLoss: 1.807061\tClass Loss: 1.493753\tDomain Loss: 0.313308\n",
            "[12768/60000 (23%)]\tLoss: 1.805913\tClass Loss: 1.492547\tDomain Loss: 0.313366\n",
            "[14368/60000 (26%)]\tLoss: 1.806644\tClass Loss: 1.493366\tDomain Loss: 0.313278\n",
            "[15968/60000 (29%)]\tLoss: 1.774540\tClass Loss: 1.461225\tDomain Loss: 0.313316\n",
            "[17568/60000 (32%)]\tLoss: 1.807827\tClass Loss: 1.494554\tDomain Loss: 0.313273\n",
            "[19168/60000 (35%)]\tLoss: 1.776650\tClass Loss: 1.463386\tDomain Loss: 0.313264\n",
            "[20768/60000 (38%)]\tLoss: 1.789377\tClass Loss: 1.476111\tDomain Loss: 0.313266\n",
            "[22368/60000 (41%)]\tLoss: 1.806107\tClass Loss: 1.492842\tDomain Loss: 0.313264\n",
            "[23968/60000 (44%)]\tLoss: 1.808221\tClass Loss: 1.494958\tDomain Loss: 0.313263\n",
            "[25568/60000 (46%)]\tLoss: 1.841228\tClass Loss: 1.527956\tDomain Loss: 0.313273\n",
            "[27168/60000 (49%)]\tLoss: 1.820823\tClass Loss: 1.507546\tDomain Loss: 0.313277\n",
            "[28768/60000 (52%)]\tLoss: 1.807123\tClass Loss: 1.493857\tDomain Loss: 0.313266\n",
            "[30368/60000 (55%)]\tLoss: 1.776883\tClass Loss: 1.463607\tDomain Loss: 0.313276\n",
            "[31968/60000 (58%)]\tLoss: 1.786032\tClass Loss: 1.472752\tDomain Loss: 0.313280\n",
            "[33568/60000 (61%)]\tLoss: 1.803040\tClass Loss: 1.489742\tDomain Loss: 0.313298\n",
            "[35168/60000 (64%)]\tLoss: 1.821331\tClass Loss: 1.508064\tDomain Loss: 0.313267\n",
            "[36768/60000 (67%)]\tLoss: 1.791497\tClass Loss: 1.478231\tDomain Loss: 0.313266\n",
            "[38368/60000 (70%)]\tLoss: 1.831201\tClass Loss: 1.517936\tDomain Loss: 0.313264\n",
            "[39968/60000 (73%)]\tLoss: 1.778908\tClass Loss: 1.465084\tDomain Loss: 0.313824\n",
            "[41568/60000 (76%)]\tLoss: 1.775121\tClass Loss: 1.461809\tDomain Loss: 0.313311\n",
            "[43168/60000 (78%)]\tLoss: 1.781367\tClass Loss: 1.467990\tDomain Loss: 0.313377\n",
            "[44768/60000 (81%)]\tLoss: 1.774878\tClass Loss: 1.461608\tDomain Loss: 0.313270\n",
            "[46368/60000 (84%)]\tLoss: 1.867228\tClass Loss: 1.552975\tDomain Loss: 0.314254\n",
            "[47968/60000 (87%)]\tLoss: 1.816090\tClass Loss: 1.502826\tDomain Loss: 0.313264\n",
            "[49568/60000 (90%)]\tLoss: 1.805677\tClass Loss: 1.492412\tDomain Loss: 0.313265\n",
            "[51168/60000 (93%)]\tLoss: 1.813827\tClass Loss: 1.500554\tDomain Loss: 0.313274\n",
            "[52768/60000 (96%)]\tLoss: 1.851825\tClass Loss: 1.538362\tDomain Loss: 0.313464\n",
            "[54368/60000 (99%)]\tLoss: 1.827045\tClass Loss: 1.513765\tDomain Loss: 0.313280\n",
            "Epoch : 2\n",
            "[1568/60000 (3%)]\tLoss: 1.774423\tClass Loss: 1.461157\tDomain Loss: 0.313266\n",
            "[3168/60000 (6%)]\tLoss: 1.775637\tClass Loss: 1.462338\tDomain Loss: 0.313299\n",
            "[4768/60000 (9%)]\tLoss: 1.818051\tClass Loss: 1.504777\tDomain Loss: 0.313274\n",
            "[6368/60000 (12%)]\tLoss: 1.787596\tClass Loss: 1.474333\tDomain Loss: 0.313262\n",
            "[7968/60000 (14%)]\tLoss: 1.800566\tClass Loss: 1.487201\tDomain Loss: 0.313365\n",
            "[9568/60000 (17%)]\tLoss: 1.774420\tClass Loss: 1.461151\tDomain Loss: 0.313269\n",
            "[11168/60000 (20%)]\tLoss: 1.804832\tClass Loss: 1.491544\tDomain Loss: 0.313288\n",
            "[12768/60000 (23%)]\tLoss: 1.805564\tClass Loss: 1.492274\tDomain Loss: 0.313291\n",
            "[14368/60000 (26%)]\tLoss: 1.774459\tClass Loss: 1.461190\tDomain Loss: 0.313269\n",
            "[15968/60000 (29%)]\tLoss: 1.774440\tClass Loss: 1.461175\tDomain Loss: 0.313264\n",
            "[17568/60000 (32%)]\tLoss: 1.783410\tClass Loss: 1.470094\tDomain Loss: 0.313316\n",
            "[19168/60000 (35%)]\tLoss: 1.774750\tClass Loss: 1.461471\tDomain Loss: 0.313279\n",
            "[20768/60000 (38%)]\tLoss: 1.805592\tClass Loss: 1.492308\tDomain Loss: 0.313284\n",
            "[22368/60000 (41%)]\tLoss: 1.836644\tClass Loss: 1.523371\tDomain Loss: 0.313273\n",
            "[23968/60000 (44%)]\tLoss: 1.851051\tClass Loss: 1.522279\tDomain Loss: 0.328772\n",
            "[25568/60000 (46%)]\tLoss: 1.808237\tClass Loss: 1.494927\tDomain Loss: 0.313310\n",
            "[27168/60000 (49%)]\tLoss: 1.792652\tClass Loss: 1.479371\tDomain Loss: 0.313281\n",
            "[28768/60000 (52%)]\tLoss: 1.774478\tClass Loss: 1.461214\tDomain Loss: 0.313265\n",
            "[30368/60000 (55%)]\tLoss: 1.805588\tClass Loss: 1.492295\tDomain Loss: 0.313293\n",
            "[31968/60000 (58%)]\tLoss: 1.778268\tClass Loss: 1.465003\tDomain Loss: 0.313265\n",
            "[33568/60000 (61%)]\tLoss: 1.775280\tClass Loss: 1.462007\tDomain Loss: 0.313273\n",
            "[35168/60000 (64%)]\tLoss: 1.834264\tClass Loss: 1.520977\tDomain Loss: 0.313288\n",
            "[36768/60000 (67%)]\tLoss: 1.784543\tClass Loss: 1.471218\tDomain Loss: 0.313325\n",
            "[38368/60000 (70%)]\tLoss: 1.774420\tClass Loss: 1.461152\tDomain Loss: 0.313268\n",
            "[39968/60000 (73%)]\tLoss: 1.786145\tClass Loss: 1.471856\tDomain Loss: 0.314289\n",
            "[41568/60000 (76%)]\tLoss: 1.775463\tClass Loss: 1.462196\tDomain Loss: 0.313267\n",
            "[43168/60000 (78%)]\tLoss: 1.774930\tClass Loss: 1.461627\tDomain Loss: 0.313302\n",
            "[44768/60000 (81%)]\tLoss: 1.807296\tClass Loss: 1.493778\tDomain Loss: 0.313519\n",
            "[46368/60000 (84%)]\tLoss: 1.835158\tClass Loss: 1.521865\tDomain Loss: 0.313294\n",
            "[47968/60000 (87%)]\tLoss: 1.774509\tClass Loss: 1.461234\tDomain Loss: 0.313275\n",
            "[49568/60000 (90%)]\tLoss: 1.804531\tClass Loss: 1.491247\tDomain Loss: 0.313284\n",
            "[51168/60000 (93%)]\tLoss: 1.778357\tClass Loss: 1.465035\tDomain Loss: 0.313321\n",
            "[52768/60000 (96%)]\tLoss: 1.774808\tClass Loss: 1.461541\tDomain Loss: 0.313267\n",
            "[54368/60000 (99%)]\tLoss: 1.774512\tClass Loss: 1.461221\tDomain Loss: 0.313291\n",
            "Epoch : 3\n",
            "[1568/60000 (3%)]\tLoss: 1.805981\tClass Loss: 1.492697\tDomain Loss: 0.313284\n",
            "[3168/60000 (6%)]\tLoss: 1.793104\tClass Loss: 1.479834\tDomain Loss: 0.313270\n",
            "[4768/60000 (9%)]\tLoss: 1.774577\tClass Loss: 1.461176\tDomain Loss: 0.313401\n",
            "[6368/60000 (12%)]\tLoss: 1.803616\tClass Loss: 1.490218\tDomain Loss: 0.313398\n",
            "[7968/60000 (14%)]\tLoss: 1.806428\tClass Loss: 1.493155\tDomain Loss: 0.313273\n",
            "[9568/60000 (17%)]\tLoss: 1.809883\tClass Loss: 1.496618\tDomain Loss: 0.313266\n",
            "[11168/60000 (20%)]\tLoss: 1.808047\tClass Loss: 1.494745\tDomain Loss: 0.313302\n",
            "[12768/60000 (23%)]\tLoss: 1.834751\tClass Loss: 1.521446\tDomain Loss: 0.313305\n",
            "[14368/60000 (26%)]\tLoss: 1.775483\tClass Loss: 1.462218\tDomain Loss: 0.313265\n",
            "[15968/60000 (29%)]\tLoss: 1.774631\tClass Loss: 1.461334\tDomain Loss: 0.313297\n",
            "[17568/60000 (32%)]\tLoss: 1.774617\tClass Loss: 1.461243\tDomain Loss: 0.313374\n",
            "[19168/60000 (35%)]\tLoss: 1.774819\tClass Loss: 1.461520\tDomain Loss: 0.313299\n",
            "[20768/60000 (38%)]\tLoss: 1.776991\tClass Loss: 1.463666\tDomain Loss: 0.313324\n",
            "[22368/60000 (41%)]\tLoss: 1.776847\tClass Loss: 1.463570\tDomain Loss: 0.313277\n",
            "[23968/60000 (44%)]\tLoss: 1.774729\tClass Loss: 1.461421\tDomain Loss: 0.313308\n",
            "[25568/60000 (46%)]\tLoss: 1.813050\tClass Loss: 1.499778\tDomain Loss: 0.313272\n",
            "[27168/60000 (49%)]\tLoss: 1.777355\tClass Loss: 1.461681\tDomain Loss: 0.315674\n",
            "[28768/60000 (52%)]\tLoss: 1.774627\tClass Loss: 1.461309\tDomain Loss: 0.313319\n",
            "[30368/60000 (55%)]\tLoss: 1.774578\tClass Loss: 1.461297\tDomain Loss: 0.313282\n",
            "[31968/60000 (58%)]\tLoss: 1.794258\tClass Loss: 1.480986\tDomain Loss: 0.313272\n",
            "[33568/60000 (61%)]\tLoss: 1.775877\tClass Loss: 1.462522\tDomain Loss: 0.313355\n",
            "[35168/60000 (64%)]\tLoss: 1.774513\tClass Loss: 1.461151\tDomain Loss: 0.313362\n",
            "[36768/60000 (67%)]\tLoss: 1.774620\tClass Loss: 1.461323\tDomain Loss: 0.313297\n",
            "[38368/60000 (70%)]\tLoss: 1.849793\tClass Loss: 1.536254\tDomain Loss: 0.313539\n",
            "[39968/60000 (73%)]\tLoss: 1.774908\tClass Loss: 1.461221\tDomain Loss: 0.313687\n",
            "[41568/60000 (76%)]\tLoss: 1.774801\tClass Loss: 1.461495\tDomain Loss: 0.313306\n",
            "[43168/60000 (78%)]\tLoss: 1.803735\tClass Loss: 1.490457\tDomain Loss: 0.313278\n",
            "[44768/60000 (81%)]\tLoss: 1.783659\tClass Loss: 1.470142\tDomain Loss: 0.313517\n",
            "[46368/60000 (84%)]\tLoss: 1.774509\tClass Loss: 1.461191\tDomain Loss: 0.313318\n",
            "[47968/60000 (87%)]\tLoss: 1.774664\tClass Loss: 1.461386\tDomain Loss: 0.313279\n",
            "[49568/60000 (90%)]\tLoss: 1.775120\tClass Loss: 1.461848\tDomain Loss: 0.313271\n",
            "[51168/60000 (93%)]\tLoss: 1.775661\tClass Loss: 1.462377\tDomain Loss: 0.313284\n",
            "[52768/60000 (96%)]\tLoss: 1.774896\tClass Loss: 1.461470\tDomain Loss: 0.313426\n",
            "[54368/60000 (99%)]\tLoss: 1.774445\tClass Loss: 1.461169\tDomain Loss: 0.313275\n",
            "Epoch : 4\n",
            "[1568/60000 (3%)]\tLoss: 1.774989\tClass Loss: 1.461152\tDomain Loss: 0.313837\n",
            "[3168/60000 (6%)]\tLoss: 1.777717\tClass Loss: 1.464169\tDomain Loss: 0.313548\n",
            "[4768/60000 (9%)]\tLoss: 1.774681\tClass Loss: 1.461339\tDomain Loss: 0.313342\n",
            "[6368/60000 (12%)]\tLoss: 1.785295\tClass Loss: 1.472016\tDomain Loss: 0.313279\n",
            "[7968/60000 (14%)]\tLoss: 1.776953\tClass Loss: 1.462650\tDomain Loss: 0.314303\n",
            "[9568/60000 (17%)]\tLoss: 1.775549\tClass Loss: 1.462228\tDomain Loss: 0.313320\n",
            "[11168/60000 (20%)]\tLoss: 1.775097\tClass Loss: 1.461715\tDomain Loss: 0.313382\n",
            "[12768/60000 (23%)]\tLoss: 1.774845\tClass Loss: 1.461525\tDomain Loss: 0.313320\n",
            "[14368/60000 (26%)]\tLoss: 1.774528\tClass Loss: 1.461166\tDomain Loss: 0.313362\n",
            "[15968/60000 (29%)]\tLoss: 1.777122\tClass Loss: 1.463856\tDomain Loss: 0.313266\n",
            "[17568/60000 (32%)]\tLoss: 1.775112\tClass Loss: 1.461662\tDomain Loss: 0.313450\n",
            "[19168/60000 (35%)]\tLoss: 1.790299\tClass Loss: 1.464442\tDomain Loss: 0.325857\n",
            "[20768/60000 (38%)]\tLoss: 1.775578\tClass Loss: 1.461151\tDomain Loss: 0.314427\n",
            "[22368/60000 (41%)]\tLoss: 1.779374\tClass Loss: 1.461197\tDomain Loss: 0.318177\n",
            "[23968/60000 (44%)]\tLoss: 1.807367\tClass Loss: 1.492541\tDomain Loss: 0.314827\n",
            "[25568/60000 (46%)]\tLoss: 1.778085\tClass Loss: 1.461175\tDomain Loss: 0.316909\n",
            "[27168/60000 (49%)]\tLoss: 1.780127\tClass Loss: 1.466293\tDomain Loss: 0.313835\n",
            "[28768/60000 (52%)]\tLoss: 1.792823\tClass Loss: 1.461182\tDomain Loss: 0.331641\n",
            "[30368/60000 (55%)]\tLoss: 1.789695\tClass Loss: 1.472073\tDomain Loss: 0.317622\n",
            "[31968/60000 (58%)]\tLoss: 1.814999\tClass Loss: 1.493251\tDomain Loss: 0.321747\n",
            "[33568/60000 (61%)]\tLoss: 1.790177\tClass Loss: 1.476888\tDomain Loss: 0.313289\n",
            "[35168/60000 (64%)]\tLoss: 1.782775\tClass Loss: 1.461165\tDomain Loss: 0.321610\n",
            "[36768/60000 (67%)]\tLoss: 1.885162\tClass Loss: 1.461154\tDomain Loss: 0.424007\n",
            "[38368/60000 (70%)]\tLoss: 1.810689\tClass Loss: 1.481781\tDomain Loss: 0.328908\n",
            "[39968/60000 (73%)]\tLoss: 1.829757\tClass Loss: 1.512695\tDomain Loss: 0.317062\n",
            "[41568/60000 (76%)]\tLoss: 1.805882\tClass Loss: 1.461452\tDomain Loss: 0.344430\n",
            "[43168/60000 (78%)]\tLoss: 1.848131\tClass Loss: 1.461240\tDomain Loss: 0.386892\n",
            "[44768/60000 (81%)]\tLoss: 2.261162\tClass Loss: 1.466195\tDomain Loss: 0.794967\n",
            "[46368/60000 (84%)]\tLoss: 1.825561\tClass Loss: 1.496297\tDomain Loss: 0.329264\n",
            "[47968/60000 (87%)]\tLoss: 1.795477\tClass Loss: 1.461195\tDomain Loss: 0.334282\n",
            "[49568/60000 (90%)]\tLoss: 1.846879\tClass Loss: 1.500973\tDomain Loss: 0.345907\n",
            "[51168/60000 (93%)]\tLoss: 2.062610\tClass Loss: 1.461631\tDomain Loss: 0.600979\n",
            "[52768/60000 (96%)]\tLoss: 1.836727\tClass Loss: 1.523403\tDomain Loss: 0.313324\n",
            "[54368/60000 (99%)]\tLoss: 1.879293\tClass Loss: 1.523623\tDomain Loss: 0.355670\n",
            "Epoch : 5\n",
            "[1568/60000 (3%)]\tLoss: 1.776001\tClass Loss: 1.461317\tDomain Loss: 0.314684\n",
            "[3168/60000 (6%)]\tLoss: 1.774531\tClass Loss: 1.461172\tDomain Loss: 0.313359\n",
            "[4768/60000 (9%)]\tLoss: 1.775341\tClass Loss: 1.461425\tDomain Loss: 0.313915\n",
            "[6368/60000 (12%)]\tLoss: 1.775792\tClass Loss: 1.461151\tDomain Loss: 0.314641\n",
            "[7968/60000 (14%)]\tLoss: 1.831424\tClass Loss: 1.488243\tDomain Loss: 0.343181\n",
            "[9568/60000 (17%)]\tLoss: 1.863136\tClass Loss: 1.490465\tDomain Loss: 0.372671\n",
            "[11168/60000 (20%)]\tLoss: 1.798654\tClass Loss: 1.461151\tDomain Loss: 0.337503\n",
            "[12768/60000 (23%)]\tLoss: 1.889050\tClass Loss: 1.483451\tDomain Loss: 0.405599\n",
            "[14368/60000 (26%)]\tLoss: 1.973235\tClass Loss: 1.470970\tDomain Loss: 0.502265\n",
            "[15968/60000 (29%)]\tLoss: 1.847878\tClass Loss: 1.471208\tDomain Loss: 0.376670\n",
            "[17568/60000 (32%)]\tLoss: 1.855714\tClass Loss: 1.461773\tDomain Loss: 0.393941\n",
            "[19168/60000 (35%)]\tLoss: 1.940280\tClass Loss: 1.490635\tDomain Loss: 0.449645\n",
            "[20768/60000 (38%)]\tLoss: 2.241044\tClass Loss: 1.492632\tDomain Loss: 0.748411\n",
            "[22368/60000 (41%)]\tLoss: 1.790966\tClass Loss: 1.461662\tDomain Loss: 0.329304\n",
            "[23968/60000 (44%)]\tLoss: 1.787450\tClass Loss: 1.461461\tDomain Loss: 0.325989\n",
            "[25568/60000 (46%)]\tLoss: 1.791589\tClass Loss: 1.462292\tDomain Loss: 0.329297\n",
            "[27168/60000 (49%)]\tLoss: 1.857269\tClass Loss: 1.483722\tDomain Loss: 0.373547\n",
            "[28768/60000 (52%)]\tLoss: 2.102117\tClass Loss: 1.463076\tDomain Loss: 0.639041\n",
            "[30368/60000 (55%)]\tLoss: 2.000271\tClass Loss: 1.502972\tDomain Loss: 0.497299\n",
            "[31968/60000 (58%)]\tLoss: 2.101920\tClass Loss: 1.461176\tDomain Loss: 0.640744\n",
            "[33568/60000 (61%)]\tLoss: 2.017966\tClass Loss: 1.465667\tDomain Loss: 0.552299\n",
            "[35168/60000 (64%)]\tLoss: 2.126307\tClass Loss: 1.489893\tDomain Loss: 0.636414\n",
            "[36768/60000 (67%)]\tLoss: 1.859950\tClass Loss: 1.461244\tDomain Loss: 0.398705\n",
            "[38368/60000 (70%)]\tLoss: 1.941323\tClass Loss: 1.492413\tDomain Loss: 0.448909\n",
            "[39968/60000 (73%)]\tLoss: 2.157834\tClass Loss: 1.491645\tDomain Loss: 0.666189\n",
            "[41568/60000 (76%)]\tLoss: 1.809173\tClass Loss: 1.461152\tDomain Loss: 0.348021\n",
            "[43168/60000 (78%)]\tLoss: 1.807182\tClass Loss: 1.481287\tDomain Loss: 0.325896\n",
            "[44768/60000 (81%)]\tLoss: 2.059494\tClass Loss: 1.512617\tDomain Loss: 0.546877\n",
            "[46368/60000 (84%)]\tLoss: 2.020521\tClass Loss: 1.491919\tDomain Loss: 0.528602\n",
            "[47968/60000 (87%)]\tLoss: 2.113941\tClass Loss: 1.461437\tDomain Loss: 0.652504\n",
            "[49568/60000 (90%)]\tLoss: 1.819959\tClass Loss: 1.470825\tDomain Loss: 0.349134\n",
            "[51168/60000 (93%)]\tLoss: 1.953864\tClass Loss: 1.462148\tDomain Loss: 0.491715\n",
            "[52768/60000 (96%)]\tLoss: 1.849611\tClass Loss: 1.461237\tDomain Loss: 0.388373\n",
            "[54368/60000 (99%)]\tLoss: 1.812036\tClass Loss: 1.475862\tDomain Loss: 0.336174\n",
            "Epoch : 6\n",
            "[1568/60000 (3%)]\tLoss: 1.776964\tClass Loss: 1.461151\tDomain Loss: 0.315813\n",
            "[3168/60000 (6%)]\tLoss: 1.825966\tClass Loss: 1.470015\tDomain Loss: 0.355951\n",
            "[4768/60000 (9%)]\tLoss: 2.013287\tClass Loss: 1.461151\tDomain Loss: 0.552135\n",
            "[6368/60000 (12%)]\tLoss: 1.957941\tClass Loss: 1.492262\tDomain Loss: 0.465679\n",
            "[7968/60000 (14%)]\tLoss: 2.029901\tClass Loss: 1.482751\tDomain Loss: 0.547150\n",
            "[9568/60000 (17%)]\tLoss: 2.027987\tClass Loss: 1.461152\tDomain Loss: 0.566835\n",
            "[11168/60000 (20%)]\tLoss: 1.973605\tClass Loss: 1.464060\tDomain Loss: 0.509545\n",
            "[12768/60000 (23%)]\tLoss: 2.093296\tClass Loss: 1.461196\tDomain Loss: 0.632100\n",
            "[14368/60000 (26%)]\tLoss: 1.801153\tClass Loss: 1.487778\tDomain Loss: 0.313375\n",
            "[15968/60000 (29%)]\tLoss: 1.774639\tClass Loss: 1.461302\tDomain Loss: 0.313337\n",
            "[17568/60000 (32%)]\tLoss: 1.784143\tClass Loss: 1.461151\tDomain Loss: 0.322991\n",
            "[19168/60000 (35%)]\tLoss: 2.021909\tClass Loss: 1.461151\tDomain Loss: 0.560758\n",
            "[20768/60000 (38%)]\tLoss: 2.093095\tClass Loss: 1.461413\tDomain Loss: 0.631682\n",
            "[22368/60000 (41%)]\tLoss: 2.087356\tClass Loss: 1.461846\tDomain Loss: 0.625510\n",
            "[23968/60000 (44%)]\tLoss: 2.007695\tClass Loss: 1.499957\tDomain Loss: 0.507739\n",
            "[25568/60000 (46%)]\tLoss: 2.052421\tClass Loss: 1.508603\tDomain Loss: 0.543818\n",
            "[27168/60000 (49%)]\tLoss: 1.855537\tClass Loss: 1.503191\tDomain Loss: 0.352347\n",
            "[28768/60000 (52%)]\tLoss: 1.982130\tClass Loss: 1.495141\tDomain Loss: 0.486989\n",
            "[30368/60000 (55%)]\tLoss: 1.815118\tClass Loss: 1.469389\tDomain Loss: 0.345729\n",
            "[31968/60000 (58%)]\tLoss: 1.827309\tClass Loss: 1.461151\tDomain Loss: 0.366158\n",
            "[33568/60000 (61%)]\tLoss: 1.974443\tClass Loss: 1.461152\tDomain Loss: 0.513291\n",
            "[35168/60000 (64%)]\tLoss: 1.944002\tClass Loss: 1.461176\tDomain Loss: 0.482825\n",
            "[36768/60000 (67%)]\tLoss: 1.997309\tClass Loss: 1.492441\tDomain Loss: 0.504869\n",
            "[38368/60000 (70%)]\tLoss: 1.807614\tClass Loss: 1.492401\tDomain Loss: 0.315213\n",
            "[39968/60000 (73%)]\tLoss: 1.779675\tClass Loss: 1.461155\tDomain Loss: 0.318520\n",
            "[41568/60000 (76%)]\tLoss: 1.864579\tClass Loss: 1.482993\tDomain Loss: 0.381587\n",
            "[43168/60000 (78%)]\tLoss: 1.902394\tClass Loss: 1.465148\tDomain Loss: 0.437245\n",
            "[44768/60000 (81%)]\tLoss: 1.902394\tClass Loss: 1.493167\tDomain Loss: 0.409227\n",
            "[46368/60000 (84%)]\tLoss: 2.030985\tClass Loss: 1.492448\tDomain Loss: 0.538537\n",
            "[47968/60000 (87%)]\tLoss: 1.974128\tClass Loss: 1.476584\tDomain Loss: 0.497544\n",
            "[49568/60000 (90%)]\tLoss: 1.839940\tClass Loss: 1.461188\tDomain Loss: 0.378752\n",
            "[51168/60000 (93%)]\tLoss: 1.815319\tClass Loss: 1.461160\tDomain Loss: 0.354159\n",
            "[52768/60000 (96%)]\tLoss: 2.078372\tClass Loss: 1.475794\tDomain Loss: 0.602578\n",
            "[54368/60000 (99%)]\tLoss: 1.882797\tClass Loss: 1.481731\tDomain Loss: 0.401066\n",
            "Epoch : 7\n",
            "[1568/60000 (3%)]\tLoss: 1.997577\tClass Loss: 1.492950\tDomain Loss: 0.504628\n",
            "[3168/60000 (6%)]\tLoss: 2.013735\tClass Loss: 1.492414\tDomain Loss: 0.521321\n",
            "[4768/60000 (9%)]\tLoss: 2.193413\tClass Loss: 1.489953\tDomain Loss: 0.703460\n",
            "[6368/60000 (12%)]\tLoss: 1.876671\tClass Loss: 1.484500\tDomain Loss: 0.392172\n",
            "[7968/60000 (14%)]\tLoss: 2.065369\tClass Loss: 1.492386\tDomain Loss: 0.572983\n",
            "[9568/60000 (17%)]\tLoss: 1.908628\tClass Loss: 1.461156\tDomain Loss: 0.447472\n",
            "[11168/60000 (20%)]\tLoss: 1.961224\tClass Loss: 1.492398\tDomain Loss: 0.468827\n",
            "[12768/60000 (23%)]\tLoss: 2.078753\tClass Loss: 1.461170\tDomain Loss: 0.617583\n",
            "[14368/60000 (26%)]\tLoss: 1.987263\tClass Loss: 1.461207\tDomain Loss: 0.526056\n",
            "[15968/60000 (29%)]\tLoss: 1.954901\tClass Loss: 1.464290\tDomain Loss: 0.490612\n",
            "[17568/60000 (32%)]\tLoss: 1.857638\tClass Loss: 1.461503\tDomain Loss: 0.396135\n",
            "[19168/60000 (35%)]\tLoss: 1.951534\tClass Loss: 1.461158\tDomain Loss: 0.490375\n",
            "[20768/60000 (38%)]\tLoss: 1.891184\tClass Loss: 1.461166\tDomain Loss: 0.430017\n",
            "[22368/60000 (41%)]\tLoss: 1.948999\tClass Loss: 1.461160\tDomain Loss: 0.487839\n",
            "[23968/60000 (44%)]\tLoss: 1.906159\tClass Loss: 1.461237\tDomain Loss: 0.444922\n",
            "[25568/60000 (46%)]\tLoss: 2.008833\tClass Loss: 1.461151\tDomain Loss: 0.547682\n",
            "[27168/60000 (49%)]\tLoss: 1.892495\tClass Loss: 1.461174\tDomain Loss: 0.431320\n",
            "[28768/60000 (52%)]\tLoss: 1.925719\tClass Loss: 1.461617\tDomain Loss: 0.464103\n",
            "[30368/60000 (55%)]\tLoss: 1.966830\tClass Loss: 1.461673\tDomain Loss: 0.505157\n",
            "[31968/60000 (58%)]\tLoss: 2.125099\tClass Loss: 1.493216\tDomain Loss: 0.631883\n",
            "[33568/60000 (61%)]\tLoss: 1.932210\tClass Loss: 1.461511\tDomain Loss: 0.470699\n",
            "[35168/60000 (64%)]\tLoss: 2.030268\tClass Loss: 1.461344\tDomain Loss: 0.568923\n",
            "[36768/60000 (67%)]\tLoss: 2.011747\tClass Loss: 1.492399\tDomain Loss: 0.519348\n",
            "[38368/60000 (70%)]\tLoss: 2.161519\tClass Loss: 1.523328\tDomain Loss: 0.638190\n",
            "[39968/60000 (73%)]\tLoss: 1.935102\tClass Loss: 1.461663\tDomain Loss: 0.473439\n",
            "[41568/60000 (76%)]\tLoss: 1.940718\tClass Loss: 1.469332\tDomain Loss: 0.471386\n",
            "[43168/60000 (78%)]\tLoss: 2.029040\tClass Loss: 1.492270\tDomain Loss: 0.536770\n",
            "[44768/60000 (81%)]\tLoss: 1.909113\tClass Loss: 1.469890\tDomain Loss: 0.439222\n",
            "[46368/60000 (84%)]\tLoss: 1.917455\tClass Loss: 1.461228\tDomain Loss: 0.456227\n",
            "[47968/60000 (87%)]\tLoss: 1.960775\tClass Loss: 1.461152\tDomain Loss: 0.499624\n",
            "[49568/60000 (90%)]\tLoss: 1.960137\tClass Loss: 1.481719\tDomain Loss: 0.478418\n",
            "[51168/60000 (93%)]\tLoss: 1.952288\tClass Loss: 1.461156\tDomain Loss: 0.491132\n",
            "[52768/60000 (96%)]\tLoss: 2.006487\tClass Loss: 1.462000\tDomain Loss: 0.544487\n",
            "[54368/60000 (99%)]\tLoss: 1.882576\tClass Loss: 1.493209\tDomain Loss: 0.389368\n",
            "Epoch : 8\n",
            "[1568/60000 (3%)]\tLoss: 1.960213\tClass Loss: 1.492470\tDomain Loss: 0.467744\n",
            "[3168/60000 (6%)]\tLoss: 1.981458\tClass Loss: 1.475157\tDomain Loss: 0.506301\n",
            "[4768/60000 (9%)]\tLoss: 1.955984\tClass Loss: 1.523647\tDomain Loss: 0.432337\n",
            "[6368/60000 (12%)]\tLoss: 1.904376\tClass Loss: 1.461151\tDomain Loss: 0.443225\n",
            "[7968/60000 (14%)]\tLoss: 1.898645\tClass Loss: 1.461159\tDomain Loss: 0.437486\n",
            "[9568/60000 (17%)]\tLoss: 1.946026\tClass Loss: 1.461427\tDomain Loss: 0.484599\n",
            "[11168/60000 (20%)]\tLoss: 2.001119\tClass Loss: 1.469983\tDomain Loss: 0.531136\n",
            "[12768/60000 (23%)]\tLoss: 2.016537\tClass Loss: 1.461151\tDomain Loss: 0.555386\n",
            "[14368/60000 (26%)]\tLoss: 1.990727\tClass Loss: 1.461151\tDomain Loss: 0.529576\n",
            "[15968/60000 (29%)]\tLoss: 1.936207\tClass Loss: 1.489448\tDomain Loss: 0.446759\n",
            "[17568/60000 (32%)]\tLoss: 1.980411\tClass Loss: 1.461195\tDomain Loss: 0.519217\n",
            "[19168/60000 (35%)]\tLoss: 1.924516\tClass Loss: 1.462221\tDomain Loss: 0.462295\n",
            "[20768/60000 (38%)]\tLoss: 2.077459\tClass Loss: 1.488505\tDomain Loss: 0.588955\n",
            "[22368/60000 (41%)]\tLoss: 2.299944\tClass Loss: 1.486683\tDomain Loss: 0.813261\n",
            "[23968/60000 (44%)]\tLoss: 2.305653\tClass Loss: 1.492391\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274413\tClass Loss: 1.461152\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.275609\tClass Loss: 1.462347\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.304395\tClass Loss: 1.491165\tDomain Loss: 0.813230\n",
            "[31968/60000 (58%)]\tLoss: 2.220765\tClass Loss: 1.485709\tDomain Loss: 0.735056\n",
            "[33568/60000 (61%)]\tLoss: 2.089245\tClass Loss: 1.461151\tDomain Loss: 0.628095\n",
            "[35168/60000 (64%)]\tLoss: 2.105341\tClass Loss: 1.482354\tDomain Loss: 0.622987\n",
            "[36768/60000 (67%)]\tLoss: 1.964711\tClass Loss: 1.515173\tDomain Loss: 0.449538\n",
            "[38368/60000 (70%)]\tLoss: 1.779459\tClass Loss: 1.461151\tDomain Loss: 0.318308\n",
            "[39968/60000 (73%)]\tLoss: 1.804541\tClass Loss: 1.461156\tDomain Loss: 0.343385\n",
            "[41568/60000 (76%)]\tLoss: 2.180640\tClass Loss: 1.461420\tDomain Loss: 0.719221\n",
            "[43168/60000 (78%)]\tLoss: 2.168933\tClass Loss: 1.496102\tDomain Loss: 0.672831\n",
            "[44768/60000 (81%)]\tLoss: 2.099241\tClass Loss: 1.461152\tDomain Loss: 0.638089\n",
            "[46368/60000 (84%)]\tLoss: 1.848290\tClass Loss: 1.461151\tDomain Loss: 0.387139\n",
            "[47968/60000 (87%)]\tLoss: 1.954138\tClass Loss: 1.461151\tDomain Loss: 0.492987\n",
            "[49568/60000 (90%)]\tLoss: 2.071909\tClass Loss: 1.481252\tDomain Loss: 0.590658\n",
            "[51168/60000 (93%)]\tLoss: 1.922121\tClass Loss: 1.461151\tDomain Loss: 0.460970\n",
            "[52768/60000 (96%)]\tLoss: 1.883914\tClass Loss: 1.461151\tDomain Loss: 0.422763\n",
            "[54368/60000 (99%)]\tLoss: 1.982997\tClass Loss: 1.461152\tDomain Loss: 0.521845\n",
            "Epoch : 9\n",
            "[1568/60000 (3%)]\tLoss: 1.997163\tClass Loss: 1.497151\tDomain Loss: 0.500012\n",
            "[3168/60000 (6%)]\tLoss: 1.924003\tClass Loss: 1.461151\tDomain Loss: 0.462852\n",
            "[4768/60000 (9%)]\tLoss: 1.937123\tClass Loss: 1.463198\tDomain Loss: 0.473924\n",
            "[6368/60000 (12%)]\tLoss: 1.974817\tClass Loss: 1.492401\tDomain Loss: 0.482416\n",
            "[7968/60000 (14%)]\tLoss: 1.890406\tClass Loss: 1.495168\tDomain Loss: 0.395239\n",
            "[9568/60000 (17%)]\tLoss: 1.980928\tClass Loss: 1.485394\tDomain Loss: 0.495535\n",
            "[11168/60000 (20%)]\tLoss: 1.971110\tClass Loss: 1.461151\tDomain Loss: 0.509959\n",
            "[12768/60000 (23%)]\tLoss: 1.935772\tClass Loss: 1.461154\tDomain Loss: 0.474619\n",
            "[14368/60000 (26%)]\tLoss: 1.923473\tClass Loss: 1.461151\tDomain Loss: 0.462323\n",
            "[15968/60000 (29%)]\tLoss: 1.980781\tClass Loss: 1.516616\tDomain Loss: 0.464165\n",
            "[17568/60000 (32%)]\tLoss: 1.942489\tClass Loss: 1.492401\tDomain Loss: 0.450088\n",
            "[19168/60000 (35%)]\tLoss: 1.908551\tClass Loss: 1.461151\tDomain Loss: 0.447400\n",
            "[20768/60000 (38%)]\tLoss: 2.057177\tClass Loss: 1.505765\tDomain Loss: 0.551412\n",
            "[22368/60000 (41%)]\tLoss: 1.937402\tClass Loss: 1.461151\tDomain Loss: 0.476251\n",
            "[23968/60000 (44%)]\tLoss: 1.964075\tClass Loss: 1.461164\tDomain Loss: 0.502911\n",
            "[25568/60000 (46%)]\tLoss: 1.967355\tClass Loss: 1.461264\tDomain Loss: 0.506091\n",
            "[27168/60000 (49%)]\tLoss: 2.152148\tClass Loss: 1.520580\tDomain Loss: 0.631569\n",
            "[28768/60000 (52%)]\tLoss: 1.993902\tClass Loss: 1.461151\tDomain Loss: 0.532751\n",
            "[30368/60000 (55%)]\tLoss: 1.936327\tClass Loss: 1.523648\tDomain Loss: 0.412678\n",
            "[31968/60000 (58%)]\tLoss: 1.899203\tClass Loss: 1.492264\tDomain Loss: 0.406939\n",
            "[33568/60000 (61%)]\tLoss: 1.966019\tClass Loss: 1.492401\tDomain Loss: 0.473618\n",
            "[35168/60000 (64%)]\tLoss: 2.005138\tClass Loss: 1.461151\tDomain Loss: 0.543988\n",
            "[36768/60000 (67%)]\tLoss: 1.904529\tClass Loss: 1.461152\tDomain Loss: 0.443377\n",
            "[38368/60000 (70%)]\tLoss: 2.054694\tClass Loss: 1.503066\tDomain Loss: 0.551628\n",
            "[39968/60000 (73%)]\tLoss: 1.996039\tClass Loss: 1.461155\tDomain Loss: 0.534884\n",
            "[41568/60000 (76%)]\tLoss: 1.976024\tClass Loss: 1.520644\tDomain Loss: 0.455379\n",
            "[43168/60000 (78%)]\tLoss: 1.982207\tClass Loss: 1.461151\tDomain Loss: 0.521056\n",
            "[44768/60000 (81%)]\tLoss: 2.012994\tClass Loss: 1.467449\tDomain Loss: 0.545545\n",
            "[46368/60000 (84%)]\tLoss: 2.095571\tClass Loss: 1.518954\tDomain Loss: 0.576617\n",
            "[47968/60000 (87%)]\tLoss: 1.945207\tClass Loss: 1.490566\tDomain Loss: 0.454641\n",
            "[49568/60000 (90%)]\tLoss: 1.903332\tClass Loss: 1.461166\tDomain Loss: 0.442166\n",
            "[51168/60000 (93%)]\tLoss: 1.916776\tClass Loss: 1.461153\tDomain Loss: 0.455623\n",
            "[52768/60000 (96%)]\tLoss: 1.979540\tClass Loss: 1.493258\tDomain Loss: 0.486282\n",
            "[54368/60000 (99%)]\tLoss: 2.057407\tClass Loss: 1.483931\tDomain Loss: 0.573477\n",
            "Model test ...\n",
            "Test Results on DANN :\n",
            "\n",
            "Source Accuracy: 9834/10000 (98.34%)\n",
            "Target Accuracy: 6597/10000 (65.97%)\n",
            "Domain Accuracy: 16721/20000 (83.61%)\n",
            "\n",
            "Epoch : 10\n",
            "[1568/60000 (3%)]\tLoss: 1.979857\tClass Loss: 1.492338\tDomain Loss: 0.487519\n",
            "[3168/60000 (6%)]\tLoss: 1.967678\tClass Loss: 1.461154\tDomain Loss: 0.506524\n",
            "[4768/60000 (9%)]\tLoss: 2.040518\tClass Loss: 1.469401\tDomain Loss: 0.571117\n",
            "[6368/60000 (12%)]\tLoss: 1.954423\tClass Loss: 1.470914\tDomain Loss: 0.483510\n",
            "[7968/60000 (14%)]\tLoss: 1.969332\tClass Loss: 1.463918\tDomain Loss: 0.505414\n",
            "[9568/60000 (17%)]\tLoss: 1.967553\tClass Loss: 1.461152\tDomain Loss: 0.506401\n",
            "[11168/60000 (20%)]\tLoss: 1.951782\tClass Loss: 1.492401\tDomain Loss: 0.459382\n",
            "[12768/60000 (23%)]\tLoss: 2.012071\tClass Loss: 1.507392\tDomain Loss: 0.504679\n",
            "[14368/60000 (26%)]\tLoss: 2.096347\tClass Loss: 1.523208\tDomain Loss: 0.573139\n",
            "[15968/60000 (29%)]\tLoss: 1.955742\tClass Loss: 1.492422\tDomain Loss: 0.463320\n",
            "[17568/60000 (32%)]\tLoss: 1.963888\tClass Loss: 1.492401\tDomain Loss: 0.471488\n",
            "[19168/60000 (35%)]\tLoss: 1.887915\tClass Loss: 1.474002\tDomain Loss: 0.413913\n",
            "[20768/60000 (38%)]\tLoss: 2.030699\tClass Loss: 1.493192\tDomain Loss: 0.537506\n",
            "[22368/60000 (41%)]\tLoss: 2.079168\tClass Loss: 1.615054\tDomain Loss: 0.464115\n",
            "[23968/60000 (44%)]\tLoss: 2.053439\tClass Loss: 1.466422\tDomain Loss: 0.587017\n",
            "[25568/60000 (46%)]\tLoss: 1.979780\tClass Loss: 1.488050\tDomain Loss: 0.491730\n",
            "[27168/60000 (49%)]\tLoss: 2.017833\tClass Loss: 1.461167\tDomain Loss: 0.556666\n",
            "[28768/60000 (52%)]\tLoss: 2.024155\tClass Loss: 1.483837\tDomain Loss: 0.540318\n",
            "[30368/60000 (55%)]\tLoss: 1.906458\tClass Loss: 1.471861\tDomain Loss: 0.434596\n",
            "[31968/60000 (58%)]\tLoss: 2.083869\tClass Loss: 1.462558\tDomain Loss: 0.621311\n",
            "[33568/60000 (61%)]\tLoss: 1.916709\tClass Loss: 1.462130\tDomain Loss: 0.454579\n",
            "[35168/60000 (64%)]\tLoss: 2.108366\tClass Loss: 1.487772\tDomain Loss: 0.620594\n",
            "[36768/60000 (67%)]\tLoss: 2.069966\tClass Loss: 1.461753\tDomain Loss: 0.608213\n",
            "[38368/60000 (70%)]\tLoss: 2.018311\tClass Loss: 1.462115\tDomain Loss: 0.556196\n",
            "[39968/60000 (73%)]\tLoss: 2.073271\tClass Loss: 1.556482\tDomain Loss: 0.516789\n",
            "[41568/60000 (76%)]\tLoss: 1.930312\tClass Loss: 1.493861\tDomain Loss: 0.436451\n",
            "[43168/60000 (78%)]\tLoss: 1.888811\tClass Loss: 1.474013\tDomain Loss: 0.414798\n",
            "[44768/60000 (81%)]\tLoss: 2.041668\tClass Loss: 1.522044\tDomain Loss: 0.519624\n",
            "[46368/60000 (84%)]\tLoss: 2.048053\tClass Loss: 1.461151\tDomain Loss: 0.586902\n",
            "[47968/60000 (87%)]\tLoss: 2.067288\tClass Loss: 1.494079\tDomain Loss: 0.573209\n",
            "[49568/60000 (90%)]\tLoss: 2.106527\tClass Loss: 1.461151\tDomain Loss: 0.645376\n",
            "[51168/60000 (93%)]\tLoss: 2.079879\tClass Loss: 1.461151\tDomain Loss: 0.618728\n",
            "[52768/60000 (96%)]\tLoss: 1.953788\tClass Loss: 1.461151\tDomain Loss: 0.492637\n",
            "[54368/60000 (99%)]\tLoss: 1.970359\tClass Loss: 1.531622\tDomain Loss: 0.438736\n",
            "Epoch : 11\n",
            "[1568/60000 (3%)]\tLoss: 1.975517\tClass Loss: 1.488427\tDomain Loss: 0.487090\n",
            "[3168/60000 (6%)]\tLoss: 1.942214\tClass Loss: 1.461152\tDomain Loss: 0.481062\n",
            "[4768/60000 (9%)]\tLoss: 1.922282\tClass Loss: 1.461172\tDomain Loss: 0.461111\n",
            "[6368/60000 (12%)]\tLoss: 1.933564\tClass Loss: 1.492418\tDomain Loss: 0.441145\n",
            "[7968/60000 (14%)]\tLoss: 2.041554\tClass Loss: 1.461151\tDomain Loss: 0.580404\n",
            "[9568/60000 (17%)]\tLoss: 2.031077\tClass Loss: 1.523651\tDomain Loss: 0.507426\n",
            "[11168/60000 (20%)]\tLoss: 1.921568\tClass Loss: 1.461171\tDomain Loss: 0.460397\n",
            "[12768/60000 (23%)]\tLoss: 2.051858\tClass Loss: 1.461151\tDomain Loss: 0.590707\n",
            "[14368/60000 (26%)]\tLoss: 2.028834\tClass Loss: 1.461156\tDomain Loss: 0.567678\n",
            "[15968/60000 (29%)]\tLoss: 2.005994\tClass Loss: 1.461159\tDomain Loss: 0.544836\n",
            "[17568/60000 (32%)]\tLoss: 1.955420\tClass Loss: 1.461210\tDomain Loss: 0.494210\n",
            "[19168/60000 (35%)]\tLoss: 1.987214\tClass Loss: 1.510315\tDomain Loss: 0.476899\n",
            "[20768/60000 (38%)]\tLoss: 2.033999\tClass Loss: 1.491501\tDomain Loss: 0.542498\n",
            "[22368/60000 (41%)]\tLoss: 1.992551\tClass Loss: 1.461151\tDomain Loss: 0.531400\n",
            "[23968/60000 (44%)]\tLoss: 2.011585\tClass Loss: 1.461167\tDomain Loss: 0.550418\n",
            "[25568/60000 (46%)]\tLoss: 2.036276\tClass Loss: 1.461810\tDomain Loss: 0.574465\n",
            "[27168/60000 (49%)]\tLoss: 1.964356\tClass Loss: 1.461153\tDomain Loss: 0.503203\n",
            "[28768/60000 (52%)]\tLoss: 1.958317\tClass Loss: 1.464128\tDomain Loss: 0.494189\n",
            "[30368/60000 (55%)]\tLoss: 2.067497\tClass Loss: 1.484991\tDomain Loss: 0.582506\n",
            "[31968/60000 (58%)]\tLoss: 2.013858\tClass Loss: 1.492401\tDomain Loss: 0.521457\n",
            "[33568/60000 (61%)]\tLoss: 2.041464\tClass Loss: 1.461520\tDomain Loss: 0.579944\n",
            "[35168/60000 (64%)]\tLoss: 1.965859\tClass Loss: 1.461993\tDomain Loss: 0.503866\n",
            "[36768/60000 (67%)]\tLoss: 2.129425\tClass Loss: 1.472975\tDomain Loss: 0.656450\n",
            "[38368/60000 (70%)]\tLoss: 2.060709\tClass Loss: 1.462868\tDomain Loss: 0.597842\n",
            "[39968/60000 (73%)]\tLoss: 1.934268\tClass Loss: 1.492280\tDomain Loss: 0.441989\n",
            "[41568/60000 (76%)]\tLoss: 2.057400\tClass Loss: 1.461327\tDomain Loss: 0.596073\n",
            "[43168/60000 (78%)]\tLoss: 1.960078\tClass Loss: 1.498353\tDomain Loss: 0.461725\n",
            "[44768/60000 (81%)]\tLoss: 2.062081\tClass Loss: 1.496074\tDomain Loss: 0.566007\n",
            "[46368/60000 (84%)]\tLoss: 2.042512\tClass Loss: 1.464082\tDomain Loss: 0.578429\n",
            "[47968/60000 (87%)]\tLoss: 1.995850\tClass Loss: 1.492012\tDomain Loss: 0.503838\n",
            "[49568/60000 (90%)]\tLoss: 2.094435\tClass Loss: 1.492401\tDomain Loss: 0.602034\n",
            "[51168/60000 (93%)]\tLoss: 1.938325\tClass Loss: 1.461638\tDomain Loss: 0.476687\n",
            "[52768/60000 (96%)]\tLoss: 1.951403\tClass Loss: 1.461275\tDomain Loss: 0.490128\n",
            "[54368/60000 (99%)]\tLoss: 1.991268\tClass Loss: 1.465959\tDomain Loss: 0.525310\n",
            "Epoch : 12\n",
            "[1568/60000 (3%)]\tLoss: 2.152365\tClass Loss: 1.465510\tDomain Loss: 0.686855\n",
            "[3168/60000 (6%)]\tLoss: 2.007608\tClass Loss: 1.511258\tDomain Loss: 0.496350\n",
            "[4768/60000 (9%)]\tLoss: 2.035045\tClass Loss: 1.461157\tDomain Loss: 0.573888\n",
            "[6368/60000 (12%)]\tLoss: 2.046925\tClass Loss: 1.504160\tDomain Loss: 0.542765\n",
            "[7968/60000 (14%)]\tLoss: 1.939775\tClass Loss: 1.467317\tDomain Loss: 0.472458\n",
            "[9568/60000 (17%)]\tLoss: 2.027695\tClass Loss: 1.461504\tDomain Loss: 0.566190\n",
            "[11168/60000 (20%)]\tLoss: 2.040409\tClass Loss: 1.491760\tDomain Loss: 0.548649\n",
            "[12768/60000 (23%)]\tLoss: 2.028151\tClass Loss: 1.515337\tDomain Loss: 0.512814\n",
            "[14368/60000 (26%)]\tLoss: 2.073473\tClass Loss: 1.516782\tDomain Loss: 0.556691\n",
            "[15968/60000 (29%)]\tLoss: 2.122422\tClass Loss: 1.543612\tDomain Loss: 0.578809\n",
            "[17568/60000 (32%)]\tLoss: 1.964283\tClass Loss: 1.462742\tDomain Loss: 0.501541\n",
            "[19168/60000 (35%)]\tLoss: 2.116230\tClass Loss: 1.524033\tDomain Loss: 0.592197\n",
            "[20768/60000 (38%)]\tLoss: 1.991853\tClass Loss: 1.462382\tDomain Loss: 0.529472\n",
            "[22368/60000 (41%)]\tLoss: 2.071421\tClass Loss: 1.493447\tDomain Loss: 0.577974\n",
            "[23968/60000 (44%)]\tLoss: 2.235005\tClass Loss: 1.542741\tDomain Loss: 0.692264\n",
            "[25568/60000 (46%)]\tLoss: 2.228447\tClass Loss: 1.492534\tDomain Loss: 0.735914\n",
            "[27168/60000 (49%)]\tLoss: 2.550883\tClass Loss: 1.487895\tDomain Loss: 1.062988\n",
            "[28768/60000 (52%)]\tLoss: 2.305657\tClass Loss: 1.492396\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274416\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.305680\tClass Loss: 1.492418\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.274416\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.274451\tClass Loss: 1.461189\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.305511\tClass Loss: 1.492250\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.274418\tClass Loss: 1.461157\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.281469\tClass Loss: 1.468208\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.303874\tClass Loss: 1.490613\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.305425\tClass Loss: 1.492164\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.274414\tClass Loss: 1.461153\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.305790\tClass Loss: 1.492529\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.283828\tClass Loss: 1.470566\tDomain Loss: 0.813262\n",
            "Epoch : 13\n",
            "[1568/60000 (3%)]\tLoss: 2.336284\tClass Loss: 1.523022\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.336899\tClass Loss: 1.523638\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.274414\tClass Loss: 1.461153\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.274424\tClass Loss: 1.461162\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.334333\tClass Loss: 1.521071\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.336880\tClass Loss: 1.523618\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.305702\tClass Loss: 1.492440\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.275051\tClass Loss: 1.461789\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.326345\tClass Loss: 1.513084\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.294883\tClass Loss: 1.481622\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274414\tClass Loss: 1.461152\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.333985\tClass Loss: 1.520724\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.275954\tClass Loss: 1.462693\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.336880\tClass Loss: 1.523618\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.276404\tClass Loss: 1.463142\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.326936\tClass Loss: 1.513674\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.305009\tClass Loss: 1.491748\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274409\tClass Loss: 1.461151\tDomain Loss: 0.813258\n",
            "[44768/60000 (81%)]\tLoss: 2.284949\tClass Loss: 1.471688\tDomain Loss: 0.813261\n",
            "[46368/60000 (84%)]\tLoss: 2.286674\tClass Loss: 1.461151\tDomain Loss: 0.825523\n",
            "[47968/60000 (87%)]\tLoss: 2.248542\tClass Loss: 1.475701\tDomain Loss: 0.772841\n",
            "[49568/60000 (90%)]\tLoss: 2.292200\tClass Loss: 1.461179\tDomain Loss: 0.831021\n",
            "[51168/60000 (93%)]\tLoss: 2.132302\tClass Loss: 1.492524\tDomain Loss: 0.639778\n",
            "[52768/60000 (96%)]\tLoss: 1.938503\tClass Loss: 1.486947\tDomain Loss: 0.451556\n",
            "[54368/60000 (99%)]\tLoss: 2.417310\tClass Loss: 1.461151\tDomain Loss: 0.956159\n",
            "Epoch : 14\n",
            "[1568/60000 (3%)]\tLoss: 2.436516\tClass Loss: 1.461751\tDomain Loss: 0.974764\n",
            "[3168/60000 (6%)]\tLoss: 2.219032\tClass Loss: 1.560266\tDomain Loss: 0.658766\n",
            "[4768/60000 (9%)]\tLoss: 2.102620\tClass Loss: 1.461151\tDomain Loss: 0.641469\n",
            "[6368/60000 (12%)]\tLoss: 2.059505\tClass Loss: 1.461919\tDomain Loss: 0.597586\n",
            "[7968/60000 (14%)]\tLoss: 2.087880\tClass Loss: 1.511735\tDomain Loss: 0.576145\n",
            "[9568/60000 (17%)]\tLoss: 2.196299\tClass Loss: 1.461163\tDomain Loss: 0.735137\n",
            "[11168/60000 (20%)]\tLoss: 2.253185\tClass Loss: 1.465457\tDomain Loss: 0.787728\n",
            "[12768/60000 (23%)]\tLoss: 2.285567\tClass Loss: 1.483163\tDomain Loss: 0.802404\n",
            "[14368/60000 (26%)]\tLoss: 2.245008\tClass Loss: 1.462649\tDomain Loss: 0.782359\n",
            "[15968/60000 (29%)]\tLoss: 2.289939\tClass Loss: 1.492399\tDomain Loss: 0.797540\n",
            "[17568/60000 (32%)]\tLoss: 2.321283\tClass Loss: 1.523646\tDomain Loss: 0.797637\n",
            "[19168/60000 (35%)]\tLoss: 2.259674\tClass Loss: 1.462254\tDomain Loss: 0.797420\n",
            "[20768/60000 (38%)]\tLoss: 2.140067\tClass Loss: 1.492400\tDomain Loss: 0.647667\n",
            "[22368/60000 (41%)]\tLoss: 2.336903\tClass Loss: 1.523641\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.272969\tClass Loss: 1.461151\tDomain Loss: 0.811818\n",
            "[27168/60000 (49%)]\tLoss: 2.274410\tClass Loss: 1.461151\tDomain Loss: 0.813260\n",
            "[28768/60000 (52%)]\tLoss: 2.227536\tClass Loss: 1.461151\tDomain Loss: 0.766385\n",
            "[30368/60000 (55%)]\tLoss: 2.344723\tClass Loss: 1.492400\tDomain Loss: 0.852323\n",
            "[31968/60000 (58%)]\tLoss: 2.168219\tClass Loss: 1.518409\tDomain Loss: 0.649810\n",
            "[33568/60000 (61%)]\tLoss: 1.994090\tClass Loss: 1.492401\tDomain Loss: 0.501689\n",
            "[35168/60000 (64%)]\tLoss: 2.245882\tClass Loss: 1.494634\tDomain Loss: 0.751248\n",
            "[36768/60000 (67%)]\tLoss: 2.306750\tClass Loss: 1.522095\tDomain Loss: 0.784655\n",
            "[38368/60000 (70%)]\tLoss: 2.368161\tClass Loss: 1.554900\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.322033\tClass Loss: 1.493147\tDomain Loss: 0.828887\n",
            "[41568/60000 (76%)]\tLoss: 2.277392\tClass Loss: 1.464130\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.289779\tClass Loss: 1.461151\tDomain Loss: 0.828628\n",
            "[44768/60000 (81%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.501271\tClass Loss: 1.461162\tDomain Loss: 1.040108\n",
            "[47968/60000 (87%)]\tLoss: 2.295220\tClass Loss: 1.481958\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.274538\tClass Loss: 1.461277\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.274472\tClass Loss: 1.461211\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.336912\tClass Loss: 1.523651\tDomain Loss: 0.813262\n",
            "Epoch : 15\n",
            "[1568/60000 (3%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.327511\tClass Loss: 1.514250\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.274415\tClass Loss: 1.461153\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.368080\tClass Loss: 1.554819\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.314224\tClass Loss: 1.500960\tDomain Loss: 0.813264\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.305650\tClass Loss: 1.492389\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.367091\tClass Loss: 1.553829\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274426\tClass Loss: 1.461164\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.336734\tClass Loss: 1.523472\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274523\tClass Loss: 1.461151\tDomain Loss: 0.813373\n",
            "[35168/60000 (64%)]\tLoss: 2.274450\tClass Loss: 1.461189\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.315601\tClass Loss: 1.502339\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.322749\tClass Loss: 1.509488\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.321287\tClass Loss: 1.523651\tDomain Loss: 0.797637\n",
            "[46368/60000 (84%)]\tLoss: 2.346998\tClass Loss: 1.533737\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.274414\tClass Loss: 1.461152\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.306589\tClass Loss: 1.493327\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.274413\tClass Loss: 1.461152\tDomain Loss: 0.813262\n",
            "Epoch : 16\n",
            "[1568/60000 (3%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.305673\tClass Loss: 1.492411\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.282124\tClass Loss: 1.468862\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.280224\tClass Loss: 1.466963\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.274415\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.305654\tClass Loss: 1.492392\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.304992\tClass Loss: 1.491731\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.305668\tClass Loss: 1.492407\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.337418\tClass Loss: 1.524156\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.314324\tClass Loss: 1.501063\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.274437\tClass Loss: 1.461176\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274627\tClass Loss: 1.461365\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.305897\tClass Loss: 1.492636\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.289099\tClass Loss: 1.475838\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.317860\tClass Loss: 1.504599\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.304389\tClass Loss: 1.491128\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.281502\tClass Loss: 1.468241\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.304109\tClass Loss: 1.490847\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274414\tClass Loss: 1.461153\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.306843\tClass Loss: 1.493582\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.305662\tClass Loss: 1.492400\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.278478\tClass Loss: 1.465216\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.305858\tClass Loss: 1.492596\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "Epoch : 17\n",
            "[1568/60000 (3%)]\tLoss: 2.305423\tClass Loss: 1.492161\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.302118\tClass Loss: 1.488856\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.276232\tClass Loss: 1.462970\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.308848\tClass Loss: 1.495587\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.326416\tClass Loss: 1.513154\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274419\tClass Loss: 1.461157\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.319123\tClass Loss: 1.505862\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.354925\tClass Loss: 1.541664\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.308107\tClass Loss: 1.494845\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.288409\tClass Loss: 1.475148\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.274523\tClass Loss: 1.461262\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.309204\tClass Loss: 1.495942\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.277780\tClass Loss: 1.464518\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.274417\tClass Loss: 1.461155\tDomain Loss: 0.813262\n",
            "Epoch : 18\n",
            "[1568/60000 (3%)]\tLoss: 2.336900\tClass Loss: 1.523638\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.288870\tClass Loss: 1.475609\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.274448\tClass Loss: 1.461186\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.274720\tClass Loss: 1.461458\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.274415\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.305664\tClass Loss: 1.492402\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.274414\tClass Loss: 1.461152\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274415\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274417\tClass Loss: 1.461155\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274611\tClass Loss: 1.461350\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.295233\tClass Loss: 1.481971\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.336906\tClass Loss: 1.523644\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.274415\tClass Loss: 1.461154\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.274430\tClass Loss: 1.461168\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "Epoch : 19\n",
            "[1568/60000 (3%)]\tLoss: 2.305555\tClass Loss: 1.492293\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.305924\tClass Loss: 1.492663\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.274440\tClass Loss: 1.461179\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.305159\tClass Loss: 1.491898\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.274440\tClass Loss: 1.461178\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.304113\tClass Loss: 1.490852\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.336912\tClass Loss: 1.523651\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.283814\tClass Loss: 1.470553\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274418\tClass Loss: 1.461156\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 2.305157\tClass Loss: 1.491895\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.290037\tClass Loss: 1.492401\tDomain Loss: 0.797637\n",
            "[44768/60000 (81%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.275167\tClass Loss: 1.461906\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.274431\tClass Loss: 1.461169\tDomain Loss: 0.813262\n",
            "[49568/60000 (90%)]\tLoss: 2.329648\tClass Loss: 1.516387\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[52768/60000 (96%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[54368/60000 (99%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "Model test ...\n",
            "Test Results on DANN :\n",
            "\n",
            "Source Accuracy: 9894/10000 (98.94%)\n",
            "Target Accuracy: 6460/10000 (64.60%)\n",
            "Domain Accuracy: 10017/20000 (50.09%)\n",
            "\n",
            "Epoch : 20\n",
            "[1568/60000 (3%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[3168/60000 (6%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[4768/60000 (9%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[6368/60000 (12%)]\tLoss: 2.305668\tClass Loss: 1.492406\tDomain Loss: 0.813262\n",
            "[7968/60000 (14%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[9568/60000 (17%)]\tLoss: 2.305469\tClass Loss: 1.492208\tDomain Loss: 0.813262\n",
            "[11168/60000 (20%)]\tLoss: 2.305662\tClass Loss: 1.492401\tDomain Loss: 0.813262\n",
            "[12768/60000 (23%)]\tLoss: 2.282132\tClass Loss: 1.468870\tDomain Loss: 0.813262\n",
            "[14368/60000 (26%)]\tLoss: 2.274508\tClass Loss: 1.461246\tDomain Loss: 0.813262\n",
            "[15968/60000 (29%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[17568/60000 (32%)]\tLoss: 2.274437\tClass Loss: 1.461176\tDomain Loss: 0.813262\n",
            "[19168/60000 (35%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[20768/60000 (38%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[22368/60000 (41%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[23968/60000 (44%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[25568/60000 (46%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[27168/60000 (49%)]\tLoss: 2.305652\tClass Loss: 1.492390\tDomain Loss: 0.813262\n",
            "[28768/60000 (52%)]\tLoss: 2.305661\tClass Loss: 1.492399\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 2.274413\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 2.258787\tClass Loss: 1.461151\tDomain Loss: 0.797637\n",
            "[38368/60000 (70%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 2.305818\tClass Loss: 1.492556\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 2.274446\tClass Loss: 1.461185\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 2.274418\tClass Loss: 1.461157\tDomain Loss: 0.813262\n",
            "[47968/60000 (87%)]\tLoss: 2.290033\tClass Loss: 1.492397\tDomain Loss: 0.797637\n",
            "[49568/60000 (90%)]\tLoss: 2.274412\tClass Loss: 1.461151\tDomain Loss: 0.813262\n",
            "[51168/60000 (93%)]\tLoss: 2.180657\tClass Loss: 1.492401\tDomain Loss: 0.688256\n",
            "[52768/60000 (96%)]\tLoss: 2.087836\tClass Loss: 1.461151\tDomain Loss: 0.626685\n",
            "[54368/60000 (99%)]\tLoss: 2.042155\tClass Loss: 1.492401\tDomain Loss: 0.549754\n",
            "Epoch : 21\n",
            "[1568/60000 (3%)]\tLoss: 2.451550\tClass Loss: 1.492511\tDomain Loss: 0.959040\n",
            "[3168/60000 (6%)]\tLoss: 2.299537\tClass Loss: 1.517525\tDomain Loss: 0.782012\n",
            "[4768/60000 (9%)]\tLoss: 2.236849\tClass Loss: 1.492527\tDomain Loss: 0.744322\n",
            "[6368/60000 (12%)]\tLoss: 2.456789\tClass Loss: 1.461201\tDomain Loss: 0.995589\n",
            "[7968/60000 (14%)]\tLoss: 2.457481\tClass Loss: 1.680669\tDomain Loss: 0.776812\n",
            "[9568/60000 (17%)]\tLoss: 2.239325\tClass Loss: 1.617397\tDomain Loss: 0.621927\n",
            "[11168/60000 (20%)]\tLoss: 2.176512\tClass Loss: 1.461151\tDomain Loss: 0.715361\n",
            "[12768/60000 (23%)]\tLoss: 1.875868\tClass Loss: 1.523552\tDomain Loss: 0.352316\n",
            "[14368/60000 (26%)]\tLoss: 1.774484\tClass Loss: 1.461222\tDomain Loss: 0.313262\n",
            "[15968/60000 (29%)]\tLoss: 1.821847\tClass Loss: 1.461151\tDomain Loss: 0.360696\n",
            "[17568/60000 (32%)]\tLoss: 1.918818\tClass Loss: 1.491841\tDomain Loss: 0.426977\n",
            "[19168/60000 (35%)]\tLoss: 1.892266\tClass Loss: 1.461151\tDomain Loss: 0.431115\n",
            "[20768/60000 (38%)]\tLoss: 1.930320\tClass Loss: 1.461811\tDomain Loss: 0.468509\n",
            "[22368/60000 (41%)]\tLoss: 2.766210\tClass Loss: 2.429901\tDomain Loss: 0.336309\n",
            "[23968/60000 (44%)]\tLoss: 2.704891\tClass Loss: 2.273651\tDomain Loss: 0.431240\n",
            "[25568/60000 (46%)]\tLoss: 2.774411\tClass Loss: 2.398651\tDomain Loss: 0.375760\n",
            "[27168/60000 (49%)]\tLoss: 2.681262\tClass Loss: 2.367401\tDomain Loss: 0.313861\n",
            "[28768/60000 (52%)]\tLoss: 3.149412\tClass Loss: 2.336151\tDomain Loss: 0.813262\n",
            "[30368/60000 (55%)]\tLoss: 3.180662\tClass Loss: 2.367401\tDomain Loss: 0.813262\n",
            "[31968/60000 (58%)]\tLoss: 3.149412\tClass Loss: 2.336151\tDomain Loss: 0.813262\n",
            "[33568/60000 (61%)]\tLoss: 3.118162\tClass Loss: 2.304901\tDomain Loss: 0.813262\n",
            "[35168/60000 (64%)]\tLoss: 3.211912\tClass Loss: 2.398651\tDomain Loss: 0.813262\n",
            "[36768/60000 (67%)]\tLoss: 3.149412\tClass Loss: 2.336151\tDomain Loss: 0.813262\n",
            "[38368/60000 (70%)]\tLoss: 3.180662\tClass Loss: 2.367401\tDomain Loss: 0.813262\n",
            "[39968/60000 (73%)]\tLoss: 3.086912\tClass Loss: 2.273651\tDomain Loss: 0.813262\n",
            "[41568/60000 (76%)]\tLoss: 3.211912\tClass Loss: 2.398651\tDomain Loss: 0.813262\n",
            "[43168/60000 (78%)]\tLoss: 3.149412\tClass Loss: 2.336151\tDomain Loss: 0.813262\n",
            "[44768/60000 (81%)]\tLoss: 3.243162\tClass Loss: 2.429901\tDomain Loss: 0.813262\n",
            "[46368/60000 (84%)]\tLoss: 3.211912\tClass Loss: 2.398651\tDomain Loss: 0.813262\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-265ec84ce779>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-265ec84ce779>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-a46f9cfa8ca2>\u001b[0m in \u001b[0;36mdann\u001b[0;34m(encoder, classifier, discriminator, source_train_loader, target_train_loader, save_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdomain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "save_name = 'omg'\n",
        "\n",
        "def main():\n",
        "    source_train_loader = mnist_train_loader\n",
        "    target_train_loader = mnistm_train_loader\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        get_free_gpu()\n",
        "        print('Running GPU : {}'.format(torch.cuda.current_device()))\n",
        "        # encoder = Extractor().cuda()\n",
        "        # classifier = Classifier().cuda()\n",
        "        # discriminator = Discriminator().cuda()\n",
        "\n",
        "        # source_only(encoder, classifier, source_train_loader, target_train_loader, save_name)\n",
        "\n",
        "        encoder = Extractor().cuda()\n",
        "        classifier = Classifier().cuda()\n",
        "        discriminator = Discriminator().cuda()\n",
        "\n",
        "        dann(encoder, classifier, discriminator, source_train_loader, target_train_loader, save_name)\n",
        "\n",
        "    else:\n",
        "        print(\"There is no GPU -_-!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source only\n",
        "Test results on source_only :\n",
        "\n",
        "Source Accuracy: 9915/10000 (99.15%)\n",
        "Target Accuracy: 6219/10000 (62.19%)\n",
        "\n",
        "# DANN"
      ],
      "metadata": {
        "id": "OaWRRBdHMJYD"
      },
      "id": "OaWRRBdHMJYD"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaQL3-3k5bxx"
      },
      "id": "PaQL3-3k5bxx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}